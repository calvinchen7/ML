{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib\n",
    "import seaborn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "\n",
    "Source: https://www.kaggle.com/jemishdonda/headbrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age Range</th>\n",
       "      <th>Head Size(cm^3)</th>\n",
       "      <th>Brain Weight(grams)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4512</td>\n",
       "      <td>1530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3738</td>\n",
       "      <td>1297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4261</td>\n",
       "      <td>1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3777</td>\n",
       "      <td>1282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4177</td>\n",
       "      <td>1590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3585</td>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3785</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3559</td>\n",
       "      <td>1255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3613</td>\n",
       "      <td>1355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3982</td>\n",
       "      <td>1375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age Range  Head Size(cm^3)  Brain Weight(grams)\n",
       "0       1          1             4512                 1530\n",
       "1       1          1             3738                 1297\n",
       "2       1          1             4261                 1335\n",
       "3       1          1             3777                 1282\n",
       "4       1          1             4177                 1590\n",
       "5       1          1             3585                 1300\n",
       "6       1          1             3785                 1400\n",
       "7       1          1             3559                 1255\n",
       "8       1          1             3613                 1355\n",
       "9       1          1             3982                 1375"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_weight_data = pd.read_csv('datasets/headbrain.csv')\n",
    "\n",
    "size_weight_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_weight_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Head Size(cm^3)', 'Brain Weight(grams)'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_weight_data.drop(['Gender', 'Age Range'], axis=1, inplace=True)\n",
    "\n",
    "size_weight_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_weight_data = size_weight_data.rename(columns={'Head Size(cm^3)' : 'Head Size',\n",
    "                                                    'Brain Weight(grams)' : 'Brain Weight'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Head Size</th>\n",
       "      <th>Brain Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4512</td>\n",
       "      <td>1530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3738</td>\n",
       "      <td>1297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4261</td>\n",
       "      <td>1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3777</td>\n",
       "      <td>1282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4177</td>\n",
       "      <td>1590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Head Size  Brain Weight\n",
       "0       4512          1530\n",
       "1       3738          1297\n",
       "2       4261          1335\n",
       "3       3777          1282\n",
       "4       4177          1590"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_weight_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.scatter(size_weight_data['Head Size'], size_weight_data['Brain Weight'], s=200)\n",
    "\n",
    "plt.xlabel('Head Size', fontsize=20)\n",
    "plt.ylabel('Brain Weight', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(size_weight_data[['Head Size']], \n",
    "                                                    size_weight_data[['Brain Weight']],\n",
    "                                                    test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((189, 1), (189, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48, 1), (48, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Head Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>189.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>3622.841270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>361.195262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>2720.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>3381.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>3609.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>3858.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>4747.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Head Size\n",
       "count   189.000000\n",
       "mean   3622.841270\n",
       "std     361.195262\n",
       "min    2720.000000\n",
       "25%    3381.000000\n",
       "50%    3609.000000\n",
       "75%    3858.000000\n",
       "max    4747.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardScaler_x = StandardScaler()\n",
    "\n",
    "standardScaler_x.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1.890000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>-9.780536e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.002656e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-2.506232e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-6.713366e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-3.842252e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>6.527863e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>3.120596e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  1.890000e+02\n",
       "mean  -9.780536e-17\n",
       "std    1.002656e+00\n",
       "min   -2.506232e+00\n",
       "25%   -6.713366e-01\n",
       "50%   -3.842252e-02\n",
       "75%    6.527863e-01\n",
       "max    3.120596e+00"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = pd.DataFrame(standardScaler_x.transform(x_train))\n",
    "\n",
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.152828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.059236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-2.106497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-0.637331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.151729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.774234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>2.273935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "count  48.000000\n",
       "mean    0.152828\n",
       "std     1.059236\n",
       "min    -2.106497\n",
       "25%    -0.637331\n",
       "50%     0.151729\n",
       "75%     0.774234\n",
       "max     2.273935"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = pd.DataFrame(standardScaler_x.transform(x_test))\n",
    "\n",
    "x_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardScaler_y = StandardScaler()\n",
    "\n",
    "standardScaler_y.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1.890000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>7.988906e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.002656e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-2.720822e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-6.348438e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-9.050276e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>5.750236e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>2.953039e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  1.890000e+02\n",
       "mean   7.988906e-16\n",
       "std    1.002656e+00\n",
       "min   -2.720822e+00\n",
       "25%   -6.348438e-01\n",
       "50%   -9.050276e-03\n",
       "75%    5.750236e-01\n",
       "max    2.953039e+00"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.DataFrame(standardScaler_y.transform(y_train))\n",
    "\n",
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.073694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.018302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-2.245219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-0.568092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-0.009050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.825341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>2.577563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "count  48.000000\n",
       "mean    0.073694\n",
       "std     1.018302\n",
       "min    -2.245219\n",
       "25%    -0.568092\n",
       "50%    -0.009050\n",
       "75%     0.825341\n",
       "max     2.577563"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = pd.DataFrame(standardScaler_y.transform(y_test))\n",
    "\n",
    "y_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting values into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.tensor(x_train.values.reshape(-1, 1), dtype = torch.float)\n",
    "y_train_tensor = torch.tensor(y_train.values.reshape(-1, 1), dtype = torch.float)\n",
    "\n",
    "x_test_tensor = torch.tensor(x_test.values.reshape(-1, 1), dtype = torch.float)\n",
    "y_test_tensor = torch.tensor(y_test.values.reshape(-1, 1), dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([189, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([189, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.4683],\n",
       "        [-0.8323],\n",
       "        [ 1.2052],\n",
       "        [ 0.8138],\n",
       "        [-0.9878]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tensor[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = 1\n",
    "hidden_layer = 12\n",
    "output_layer = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/stable/nn.html#mseloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression using optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(torch.nn.Linear(input_layer, hidden_layer),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(hidden_layer, output_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration no: 0 and Loss: 67.92976379394531\n",
      "Iteration no: 1 and Loss: 67.91918182373047\n",
      "Iteration no: 2 and Loss: 67.90863800048828\n",
      "Iteration no: 3 and Loss: 67.89810180664062\n",
      "Iteration no: 4 and Loss: 67.88761901855469\n",
      "Iteration no: 5 and Loss: 67.87712097167969\n",
      "Iteration no: 6 and Loss: 67.8666763305664\n",
      "Iteration no: 7 and Loss: 67.85624694824219\n",
      "Iteration no: 8 and Loss: 67.84586334228516\n",
      "Iteration no: 9 and Loss: 67.83544921875\n",
      "Iteration no: 10 and Loss: 67.8250961303711\n",
      "Iteration no: 11 and Loss: 67.81473541259766\n",
      "Iteration no: 12 and Loss: 67.8044204711914\n",
      "Iteration no: 13 and Loss: 67.79411315917969\n",
      "Iteration no: 14 and Loss: 67.78382110595703\n",
      "Iteration no: 15 and Loss: 67.7735595703125\n",
      "Iteration no: 16 and Loss: 67.7632827758789\n",
      "Iteration no: 17 and Loss: 67.7530746459961\n",
      "Iteration no: 18 and Loss: 67.74288940429688\n",
      "Iteration no: 19 and Loss: 67.73269653320312\n",
      "Iteration no: 20 and Loss: 67.7225112915039\n",
      "Iteration no: 21 and Loss: 67.71234130859375\n",
      "Iteration no: 22 and Loss: 67.70222473144531\n",
      "Iteration no: 23 and Loss: 67.69213104248047\n",
      "Iteration no: 24 and Loss: 67.6820297241211\n",
      "Iteration no: 25 and Loss: 67.6719970703125\n",
      "Iteration no: 26 and Loss: 67.66200256347656\n",
      "Iteration no: 27 and Loss: 67.65203857421875\n",
      "Iteration no: 28 and Loss: 67.64214324951172\n",
      "Iteration no: 29 and Loss: 67.63224792480469\n",
      "Iteration no: 30 and Loss: 67.62242126464844\n",
      "Iteration no: 31 and Loss: 67.6125717163086\n",
      "Iteration no: 32 and Loss: 67.60279083251953\n",
      "Iteration no: 33 and Loss: 67.59300994873047\n",
      "Iteration no: 34 and Loss: 67.58323669433594\n",
      "Iteration no: 35 and Loss: 67.57349395751953\n",
      "Iteration no: 36 and Loss: 67.56379699707031\n",
      "Iteration no: 37 and Loss: 67.55411529541016\n",
      "Iteration no: 38 and Loss: 67.54442596435547\n",
      "Iteration no: 39 and Loss: 67.53477478027344\n",
      "Iteration no: 40 and Loss: 67.52517700195312\n",
      "Iteration no: 41 and Loss: 67.51558685302734\n",
      "Iteration no: 42 and Loss: 67.50603485107422\n",
      "Iteration no: 43 and Loss: 67.4964828491211\n",
      "Iteration no: 44 and Loss: 67.48699188232422\n",
      "Iteration no: 45 and Loss: 67.47750091552734\n",
      "Iteration no: 46 and Loss: 67.46802520751953\n",
      "Iteration no: 47 and Loss: 67.4585952758789\n",
      "Iteration no: 48 and Loss: 67.44915771484375\n",
      "Iteration no: 49 and Loss: 67.43972778320312\n",
      "Iteration no: 50 and Loss: 67.43035888671875\n",
      "Iteration no: 51 and Loss: 67.4209976196289\n",
      "Iteration no: 52 and Loss: 67.41162872314453\n",
      "Iteration no: 53 and Loss: 67.40231323242188\n",
      "Iteration no: 54 and Loss: 67.39302062988281\n",
      "Iteration no: 55 and Loss: 67.38372039794922\n",
      "Iteration no: 56 and Loss: 67.37445831298828\n",
      "Iteration no: 57 and Loss: 67.36521911621094\n",
      "Iteration no: 58 and Loss: 67.35600280761719\n",
      "Iteration no: 59 and Loss: 67.3468017578125\n",
      "Iteration no: 60 and Loss: 67.33760833740234\n",
      "Iteration no: 61 and Loss: 67.32845306396484\n",
      "Iteration no: 62 and Loss: 67.31932067871094\n",
      "Iteration no: 63 and Loss: 67.31019592285156\n",
      "Iteration no: 64 and Loss: 67.30107879638672\n",
      "Iteration no: 65 and Loss: 67.29197692871094\n",
      "Iteration no: 66 and Loss: 67.28294372558594\n",
      "Iteration no: 67 and Loss: 67.27391052246094\n",
      "Iteration no: 68 and Loss: 67.26487731933594\n",
      "Iteration no: 69 and Loss: 67.25586700439453\n",
      "Iteration no: 70 and Loss: 67.24688720703125\n",
      "Iteration no: 71 and Loss: 67.23789978027344\n",
      "Iteration no: 72 and Loss: 67.22891998291016\n",
      "Iteration no: 73 and Loss: 67.21994018554688\n",
      "Iteration no: 74 and Loss: 67.21100616455078\n",
      "Iteration no: 75 and Loss: 67.20217895507812\n",
      "Iteration no: 76 and Loss: 67.193359375\n",
      "Iteration no: 77 and Loss: 67.1845703125\n",
      "Iteration no: 78 and Loss: 67.17578125\n",
      "Iteration no: 79 and Loss: 67.16703796386719\n",
      "Iteration no: 80 and Loss: 67.15827941894531\n",
      "Iteration no: 81 and Loss: 67.1495590209961\n",
      "Iteration no: 82 and Loss: 67.14088439941406\n",
      "Iteration no: 83 and Loss: 67.1322021484375\n",
      "Iteration no: 84 and Loss: 67.12356567382812\n",
      "Iteration no: 85 and Loss: 67.11492919921875\n",
      "Iteration no: 86 and Loss: 67.10631561279297\n",
      "Iteration no: 87 and Loss: 67.09773254394531\n",
      "Iteration no: 88 and Loss: 67.08917999267578\n",
      "Iteration no: 89 and Loss: 67.08063507080078\n",
      "Iteration no: 90 and Loss: 67.07213592529297\n",
      "Iteration no: 91 and Loss: 67.0636215209961\n",
      "Iteration no: 92 and Loss: 67.05513763427734\n",
      "Iteration no: 93 and Loss: 67.04666900634766\n",
      "Iteration no: 94 and Loss: 67.03822326660156\n",
      "Iteration no: 95 and Loss: 67.02981567382812\n",
      "Iteration no: 96 and Loss: 67.02140045166016\n",
      "Iteration no: 97 and Loss: 67.01302337646484\n",
      "Iteration no: 98 and Loss: 67.0046615600586\n",
      "Iteration no: 99 and Loss: 66.99642944335938\n",
      "Iteration no: 100 and Loss: 66.98816680908203\n",
      "Iteration no: 101 and Loss: 66.97994995117188\n",
      "Iteration no: 102 and Loss: 66.97176361083984\n",
      "Iteration no: 103 and Loss: 66.96358489990234\n",
      "Iteration no: 104 and Loss: 66.95538330078125\n",
      "Iteration no: 105 and Loss: 66.94725036621094\n",
      "Iteration no: 106 and Loss: 66.93920135498047\n",
      "Iteration no: 107 and Loss: 66.93113708496094\n",
      "Iteration no: 108 and Loss: 66.92308044433594\n",
      "Iteration no: 109 and Loss: 66.91508483886719\n",
      "Iteration no: 110 and Loss: 66.90707397460938\n",
      "Iteration no: 111 and Loss: 66.89910888671875\n",
      "Iteration no: 112 and Loss: 66.89115142822266\n",
      "Iteration no: 113 and Loss: 66.8832015991211\n",
      "Iteration no: 114 and Loss: 66.87527465820312\n",
      "Iteration no: 115 and Loss: 66.86737823486328\n",
      "Iteration no: 116 and Loss: 66.85948944091797\n",
      "Iteration no: 117 and Loss: 66.85162353515625\n",
      "Iteration no: 118 and Loss: 66.8437728881836\n",
      "Iteration no: 119 and Loss: 66.83594512939453\n",
      "Iteration no: 120 and Loss: 66.8281478881836\n",
      "Iteration no: 121 and Loss: 66.82034301757812\n",
      "Iteration no: 122 and Loss: 66.81259155273438\n",
      "Iteration no: 123 and Loss: 66.80482482910156\n",
      "Iteration no: 124 and Loss: 66.79710388183594\n",
      "Iteration no: 125 and Loss: 66.78939056396484\n",
      "Iteration no: 126 and Loss: 66.78168487548828\n",
      "Iteration no: 127 and Loss: 66.7740249633789\n",
      "Iteration no: 128 and Loss: 66.76634216308594\n",
      "Iteration no: 129 and Loss: 66.75869750976562\n",
      "Iteration no: 130 and Loss: 66.7510757446289\n",
      "Iteration no: 131 and Loss: 66.74343872070312\n",
      "Iteration no: 132 and Loss: 66.7358627319336\n",
      "Iteration no: 133 and Loss: 66.7282943725586\n",
      "Iteration no: 134 and Loss: 66.72068786621094\n",
      "Iteration no: 135 and Loss: 66.71315002441406\n",
      "Iteration no: 136 and Loss: 66.70560455322266\n",
      "Iteration no: 137 and Loss: 66.69807434082031\n",
      "Iteration no: 138 and Loss: 66.69058227539062\n",
      "Iteration no: 139 and Loss: 66.68307495117188\n",
      "Iteration no: 140 and Loss: 66.67561340332031\n",
      "Iteration no: 141 and Loss: 66.66815185546875\n",
      "Iteration no: 142 and Loss: 66.66069793701172\n",
      "Iteration no: 143 and Loss: 66.65328216552734\n",
      "Iteration no: 144 and Loss: 66.64585876464844\n",
      "Iteration no: 145 and Loss: 66.63845825195312\n",
      "Iteration no: 146 and Loss: 66.63105773925781\n",
      "Iteration no: 147 and Loss: 66.62370300292969\n",
      "Iteration no: 148 and Loss: 66.6163330078125\n",
      "Iteration no: 149 and Loss: 66.60900115966797\n",
      "Iteration no: 150 and Loss: 66.6016845703125\n",
      "Iteration no: 151 and Loss: 66.59437561035156\n",
      "Iteration no: 152 and Loss: 66.5870590209961\n",
      "Iteration no: 153 and Loss: 66.57977294921875\n",
      "Iteration no: 154 and Loss: 66.57250213623047\n",
      "Iteration no: 155 and Loss: 66.56523895263672\n",
      "Iteration no: 156 and Loss: 66.5580062866211\n",
      "Iteration no: 157 and Loss: 66.55077362060547\n",
      "Iteration no: 158 and Loss: 66.54357147216797\n",
      "Iteration no: 159 and Loss: 66.5363540649414\n",
      "Iteration no: 160 and Loss: 66.52910614013672\n",
      "Iteration no: 161 and Loss: 66.5218734741211\n",
      "Iteration no: 162 and Loss: 66.5146713256836\n",
      "Iteration no: 163 and Loss: 66.50747680664062\n",
      "Iteration no: 164 and Loss: 66.50023651123047\n",
      "Iteration no: 165 and Loss: 66.49301147460938\n",
      "Iteration no: 166 and Loss: 66.48582458496094\n",
      "Iteration no: 167 and Loss: 66.47863006591797\n",
      "Iteration no: 168 and Loss: 66.47144317626953\n",
      "Iteration no: 169 and Loss: 66.4642562866211\n",
      "Iteration no: 170 and Loss: 66.45709991455078\n",
      "Iteration no: 171 and Loss: 66.44994354248047\n",
      "Iteration no: 172 and Loss: 66.44277954101562\n",
      "Iteration no: 173 and Loss: 66.43561553955078\n",
      "Iteration no: 174 and Loss: 66.428466796875\n",
      "Iteration no: 175 and Loss: 66.42132568359375\n",
      "Iteration no: 176 and Loss: 66.41419219970703\n",
      "Iteration no: 177 and Loss: 66.40705108642578\n",
      "Iteration no: 178 and Loss: 66.39993286132812\n",
      "Iteration no: 179 and Loss: 66.39282989501953\n",
      "Iteration no: 180 and Loss: 66.38573455810547\n",
      "Iteration no: 181 and Loss: 66.3786392211914\n",
      "Iteration no: 182 and Loss: 66.37156677246094\n",
      "Iteration no: 183 and Loss: 66.36449432373047\n",
      "Iteration no: 184 and Loss: 66.35742950439453\n",
      "Iteration no: 185 and Loss: 66.35037231445312\n",
      "Iteration no: 186 and Loss: 66.34333801269531\n",
      "Iteration no: 187 and Loss: 66.33634185791016\n",
      "Iteration no: 188 and Loss: 66.3293228149414\n",
      "Iteration no: 189 and Loss: 66.32232666015625\n",
      "Iteration no: 190 and Loss: 66.31539154052734\n",
      "Iteration no: 191 and Loss: 66.30840301513672\n",
      "Iteration no: 192 and Loss: 66.30145263671875\n",
      "Iteration no: 193 and Loss: 66.29450988769531\n",
      "Iteration no: 194 and Loss: 66.28758239746094\n",
      "Iteration no: 195 and Loss: 66.28065490722656\n",
      "Iteration no: 196 and Loss: 66.27375793457031\n",
      "Iteration no: 197 and Loss: 66.266845703125\n",
      "Iteration no: 198 and Loss: 66.25997161865234\n",
      "Iteration no: 199 and Loss: 66.25310516357422\n",
      "Iteration no: 200 and Loss: 66.2462387084961\n",
      "Iteration no: 201 and Loss: 66.23941040039062\n",
      "Iteration no: 202 and Loss: 66.23258209228516\n",
      "Iteration no: 203 and Loss: 66.22571563720703\n",
      "Iteration no: 204 and Loss: 66.21890258789062\n",
      "Iteration no: 205 and Loss: 66.21210479736328\n",
      "Iteration no: 206 and Loss: 66.20531463623047\n",
      "Iteration no: 207 and Loss: 66.1985092163086\n",
      "Iteration no: 208 and Loss: 66.1917495727539\n",
      "Iteration no: 209 and Loss: 66.18497467041016\n",
      "Iteration no: 210 and Loss: 66.17821502685547\n",
      "Iteration no: 211 and Loss: 66.17150115966797\n",
      "Iteration no: 212 and Loss: 66.1647720336914\n",
      "Iteration no: 213 and Loss: 66.15806579589844\n",
      "Iteration no: 214 and Loss: 66.1513671875\n",
      "Iteration no: 215 and Loss: 66.1446762084961\n",
      "Iteration no: 216 and Loss: 66.13798522949219\n",
      "Iteration no: 217 and Loss: 66.13134002685547\n",
      "Iteration no: 218 and Loss: 66.1248779296875\n",
      "Iteration no: 219 and Loss: 66.11848449707031\n",
      "Iteration no: 220 and Loss: 66.11209106445312\n",
      "Iteration no: 221 and Loss: 66.105712890625\n",
      "Iteration no: 222 and Loss: 66.0993881225586\n",
      "Iteration no: 223 and Loss: 66.09309387207031\n",
      "Iteration no: 224 and Loss: 66.0867919921875\n",
      "Iteration no: 225 and Loss: 66.08053588867188\n",
      "Iteration no: 226 and Loss: 66.07429504394531\n",
      "Iteration no: 227 and Loss: 66.06804656982422\n",
      "Iteration no: 228 and Loss: 66.06182861328125\n",
      "Iteration no: 229 and Loss: 66.05565643310547\n",
      "Iteration no: 230 and Loss: 66.04948425292969\n",
      "Iteration no: 231 and Loss: 66.04331970214844\n",
      "Iteration no: 232 and Loss: 66.03719329833984\n",
      "Iteration no: 233 and Loss: 66.03105926513672\n",
      "Iteration no: 234 and Loss: 66.02497863769531\n",
      "Iteration no: 235 and Loss: 66.01887512207031\n",
      "Iteration no: 236 and Loss: 66.01274108886719\n",
      "Iteration no: 237 and Loss: 66.00660705566406\n",
      "Iteration no: 238 and Loss: 66.00048065185547\n",
      "Iteration no: 239 and Loss: 65.99434661865234\n",
      "Iteration no: 240 and Loss: 65.98825073242188\n",
      "Iteration no: 241 and Loss: 65.98212432861328\n",
      "Iteration no: 242 and Loss: 65.97602844238281\n",
      "Iteration no: 243 and Loss: 65.96995544433594\n",
      "Iteration no: 244 and Loss: 65.96389770507812\n",
      "Iteration no: 245 and Loss: 65.95784759521484\n",
      "Iteration no: 246 and Loss: 65.95181274414062\n",
      "Iteration no: 247 and Loss: 65.9457778930664\n",
      "Iteration no: 248 and Loss: 65.93974304199219\n",
      "Iteration no: 249 and Loss: 65.9337387084961\n",
      "Iteration no: 250 and Loss: 65.92774200439453\n",
      "Iteration no: 251 and Loss: 65.92174530029297\n",
      "Iteration no: 252 and Loss: 65.9157943725586\n",
      "Iteration no: 253 and Loss: 65.90980529785156\n",
      "Iteration no: 254 and Loss: 65.90380859375\n",
      "Iteration no: 255 and Loss: 65.89781188964844\n",
      "Iteration no: 256 and Loss: 65.89183807373047\n",
      "Iteration no: 257 and Loss: 65.88584899902344\n",
      "Iteration no: 258 and Loss: 65.8798828125\n",
      "Iteration no: 259 and Loss: 65.87393951416016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration no: 260 and Loss: 65.86798858642578\n",
      "Iteration no: 261 and Loss: 65.86202239990234\n",
      "Iteration no: 262 and Loss: 65.85601806640625\n",
      "Iteration no: 263 and Loss: 65.85005187988281\n",
      "Iteration no: 264 and Loss: 65.8441390991211\n",
      "Iteration no: 265 and Loss: 65.83820343017578\n",
      "Iteration no: 266 and Loss: 65.83230590820312\n",
      "Iteration no: 267 and Loss: 65.82640838623047\n",
      "Iteration no: 268 and Loss: 65.82051849365234\n",
      "Iteration no: 269 and Loss: 65.8147201538086\n",
      "Iteration no: 270 and Loss: 65.80889129638672\n",
      "Iteration no: 271 and Loss: 65.80314636230469\n",
      "Iteration no: 272 and Loss: 65.79740142822266\n",
      "Iteration no: 273 and Loss: 65.7916259765625\n",
      "Iteration no: 274 and Loss: 65.78590393066406\n",
      "Iteration no: 275 and Loss: 65.78020477294922\n",
      "Iteration no: 276 and Loss: 65.77452087402344\n",
      "Iteration no: 277 and Loss: 65.76881408691406\n",
      "Iteration no: 278 and Loss: 65.76316833496094\n",
      "Iteration no: 279 and Loss: 65.75751495361328\n",
      "Iteration no: 280 and Loss: 65.75187683105469\n",
      "Iteration no: 281 and Loss: 65.7462387084961\n",
      "Iteration no: 282 and Loss: 65.74065399169922\n",
      "Iteration no: 283 and Loss: 65.73505401611328\n",
      "Iteration no: 284 and Loss: 65.72948455810547\n",
      "Iteration no: 285 and Loss: 65.72391510009766\n",
      "Iteration no: 286 and Loss: 65.71836853027344\n",
      "Iteration no: 287 and Loss: 65.71281433105469\n",
      "Iteration no: 288 and Loss: 65.70732879638672\n",
      "Iteration no: 289 and Loss: 65.7017822265625\n",
      "Iteration no: 290 and Loss: 65.6962890625\n",
      "Iteration no: 291 and Loss: 65.69080352783203\n",
      "Iteration no: 292 and Loss: 65.6853256225586\n",
      "Iteration no: 293 and Loss: 65.67987060546875\n",
      "Iteration no: 294 and Loss: 65.67440795898438\n",
      "Iteration no: 295 and Loss: 65.6689682006836\n",
      "Iteration no: 296 and Loss: 65.66354370117188\n",
      "Iteration no: 297 and Loss: 65.65812683105469\n",
      "Iteration no: 298 and Loss: 65.6527328491211\n",
      "Iteration no: 299 and Loss: 65.6473388671875\n",
      "Iteration no: 300 and Loss: 65.64196014404297\n",
      "Iteration no: 301 and Loss: 65.63658905029297\n",
      "Iteration no: 302 and Loss: 65.63127136230469\n",
      "Iteration no: 303 and Loss: 65.62596130371094\n",
      "Iteration no: 304 and Loss: 65.62068176269531\n",
      "Iteration no: 305 and Loss: 65.61540222167969\n",
      "Iteration no: 306 and Loss: 65.61013793945312\n",
      "Iteration no: 307 and Loss: 65.60487365722656\n",
      "Iteration no: 308 and Loss: 65.59963989257812\n",
      "Iteration no: 309 and Loss: 65.59443664550781\n",
      "Iteration no: 310 and Loss: 65.58924102783203\n",
      "Iteration no: 311 and Loss: 65.58407592773438\n",
      "Iteration no: 312 and Loss: 65.57893371582031\n",
      "Iteration no: 313 and Loss: 65.57376098632812\n",
      "Iteration no: 314 and Loss: 65.56864166259766\n",
      "Iteration no: 315 and Loss: 65.56352233886719\n",
      "Iteration no: 316 and Loss: 65.55842590332031\n",
      "Iteration no: 317 and Loss: 65.55331420898438\n",
      "Iteration no: 318 and Loss: 65.54824829101562\n",
      "Iteration no: 319 and Loss: 65.5431900024414\n",
      "Iteration no: 320 and Loss: 65.53813934326172\n",
      "Iteration no: 321 and Loss: 65.53305053710938\n",
      "Iteration no: 322 and Loss: 65.52803802490234\n",
      "Iteration no: 323 and Loss: 65.52302551269531\n",
      "Iteration no: 324 and Loss: 65.51802062988281\n",
      "Iteration no: 325 and Loss: 65.51303100585938\n",
      "Iteration no: 326 and Loss: 65.50801086425781\n",
      "Iteration no: 327 and Loss: 65.50298309326172\n",
      "Iteration no: 328 and Loss: 65.49797058105469\n",
      "Iteration no: 329 and Loss: 65.49295043945312\n",
      "Iteration no: 330 and Loss: 65.48792266845703\n",
      "Iteration no: 331 and Loss: 65.4829330444336\n",
      "Iteration no: 332 and Loss: 65.47795104980469\n",
      "Iteration no: 333 and Loss: 65.47296905517578\n",
      "Iteration no: 334 and Loss: 65.46800231933594\n",
      "Iteration no: 335 and Loss: 65.4630355834961\n",
      "Iteration no: 336 and Loss: 65.45809173583984\n",
      "Iteration no: 337 and Loss: 65.45313262939453\n",
      "Iteration no: 338 and Loss: 65.44818115234375\n",
      "Iteration no: 339 and Loss: 65.4432601928711\n",
      "Iteration no: 340 and Loss: 65.43834686279297\n",
      "Iteration no: 341 and Loss: 65.43341827392578\n",
      "Iteration no: 342 and Loss: 65.42853546142578\n",
      "Iteration no: 343 and Loss: 65.42364501953125\n",
      "Iteration no: 344 and Loss: 65.41877746582031\n",
      "Iteration no: 345 and Loss: 65.41390991210938\n",
      "Iteration no: 346 and Loss: 65.40904235839844\n",
      "Iteration no: 347 and Loss: 65.40421295166016\n",
      "Iteration no: 348 and Loss: 65.3993911743164\n",
      "Iteration no: 349 and Loss: 65.39456176757812\n",
      "Iteration no: 350 and Loss: 65.38976287841797\n",
      "Iteration no: 351 and Loss: 65.38496398925781\n",
      "Iteration no: 352 and Loss: 65.38018035888672\n",
      "Iteration no: 353 and Loss: 65.37539672851562\n",
      "Iteration no: 354 and Loss: 65.37061309814453\n",
      "Iteration no: 355 and Loss: 65.3658676147461\n",
      "Iteration no: 356 and Loss: 65.3611068725586\n",
      "Iteration no: 357 and Loss: 65.35637664794922\n",
      "Iteration no: 358 and Loss: 65.35164642333984\n",
      "Iteration no: 359 and Loss: 65.3469467163086\n",
      "Iteration no: 360 and Loss: 65.34222412109375\n",
      "Iteration no: 361 and Loss: 65.3375244140625\n",
      "Iteration no: 362 and Loss: 65.3328628540039\n",
      "Iteration no: 363 and Loss: 65.32818603515625\n",
      "Iteration no: 364 and Loss: 65.3235092163086\n",
      "Iteration no: 365 and Loss: 65.31886291503906\n",
      "Iteration no: 366 and Loss: 65.31420135498047\n",
      "Iteration no: 367 and Loss: 65.30958557128906\n",
      "Iteration no: 368 and Loss: 65.30496215820312\n",
      "Iteration no: 369 and Loss: 65.30034637451172\n",
      "Iteration no: 370 and Loss: 65.29576110839844\n",
      "Iteration no: 371 and Loss: 65.29116821289062\n",
      "Iteration no: 372 and Loss: 65.28658294677734\n",
      "Iteration no: 373 and Loss: 65.28201293945312\n",
      "Iteration no: 374 and Loss: 65.27745056152344\n",
      "Iteration no: 375 and Loss: 65.27290344238281\n",
      "Iteration no: 376 and Loss: 65.26834106445312\n",
      "Iteration no: 377 and Loss: 65.2638168334961\n",
      "Iteration no: 378 and Loss: 65.25930786132812\n",
      "Iteration no: 379 and Loss: 65.25481414794922\n",
      "Iteration no: 380 and Loss: 65.25029754638672\n",
      "Iteration no: 381 and Loss: 65.24581909179688\n",
      "Iteration no: 382 and Loss: 65.24134063720703\n",
      "Iteration no: 383 and Loss: 65.23686218261719\n",
      "Iteration no: 384 and Loss: 65.23242950439453\n",
      "Iteration no: 385 and Loss: 65.22795104980469\n",
      "Iteration no: 386 and Loss: 65.22354125976562\n",
      "Iteration no: 387 and Loss: 65.21916198730469\n",
      "Iteration no: 388 and Loss: 65.21477508544922\n",
      "Iteration no: 389 and Loss: 65.21038818359375\n",
      "Iteration no: 390 and Loss: 65.2060317993164\n",
      "Iteration no: 391 and Loss: 65.20167541503906\n",
      "Iteration no: 392 and Loss: 65.19731903076172\n",
      "Iteration no: 393 and Loss: 65.19297790527344\n",
      "Iteration no: 394 and Loss: 65.18868255615234\n",
      "Iteration no: 395 and Loss: 65.18436431884766\n",
      "Iteration no: 396 and Loss: 65.18006896972656\n",
      "Iteration no: 397 and Loss: 65.1757583618164\n",
      "Iteration no: 398 and Loss: 65.17149353027344\n",
      "Iteration no: 399 and Loss: 65.1672134399414\n",
      "Iteration no: 400 and Loss: 65.1629638671875\n",
      "Iteration no: 401 and Loss: 65.15869903564453\n",
      "Iteration no: 402 and Loss: 65.15446472167969\n",
      "Iteration no: 403 and Loss: 65.1502456665039\n",
      "Iteration no: 404 and Loss: 65.14602661132812\n",
      "Iteration no: 405 and Loss: 65.14181518554688\n",
      "Iteration no: 406 and Loss: 65.13763427734375\n",
      "Iteration no: 407 and Loss: 65.1334457397461\n",
      "Iteration no: 408 and Loss: 65.12928009033203\n",
      "Iteration no: 409 and Loss: 65.1251449584961\n",
      "Iteration no: 410 and Loss: 65.12101745605469\n",
      "Iteration no: 411 and Loss: 65.11688232421875\n",
      "Iteration no: 412 and Loss: 65.11276245117188\n",
      "Iteration no: 413 and Loss: 65.10865783691406\n",
      "Iteration no: 414 and Loss: 65.10458374023438\n",
      "Iteration no: 415 and Loss: 65.10050201416016\n",
      "Iteration no: 416 and Loss: 65.09642028808594\n",
      "Iteration no: 417 and Loss: 65.09236145019531\n",
      "Iteration no: 418 and Loss: 65.08830261230469\n",
      "Iteration no: 419 and Loss: 65.08428192138672\n",
      "Iteration no: 420 and Loss: 65.08023834228516\n",
      "Iteration no: 421 and Loss: 65.07623291015625\n",
      "Iteration no: 422 and Loss: 65.07221984863281\n",
      "Iteration no: 423 and Loss: 65.06822204589844\n",
      "Iteration no: 424 and Loss: 65.06427001953125\n",
      "Iteration no: 425 and Loss: 65.06031799316406\n",
      "Iteration no: 426 and Loss: 65.05635833740234\n",
      "Iteration no: 427 and Loss: 65.05242156982422\n",
      "Iteration no: 428 and Loss: 65.04850006103516\n",
      "Iteration no: 429 and Loss: 65.0445785522461\n",
      "Iteration no: 430 and Loss: 65.0406723022461\n",
      "Iteration no: 431 and Loss: 65.03678131103516\n",
      "Iteration no: 432 and Loss: 65.03291320800781\n",
      "Iteration no: 433 and Loss: 65.02902221679688\n",
      "Iteration no: 434 and Loss: 65.0251693725586\n",
      "Iteration no: 435 and Loss: 65.02131652832031\n",
      "Iteration no: 436 and Loss: 65.0174789428711\n",
      "Iteration no: 437 and Loss: 65.0136489868164\n",
      "Iteration no: 438 and Loss: 65.00980377197266\n",
      "Iteration no: 439 and Loss: 65.00598907470703\n",
      "Iteration no: 440 and Loss: 65.00218200683594\n",
      "Iteration no: 441 and Loss: 64.99836730957031\n",
      "Iteration no: 442 and Loss: 64.99459838867188\n",
      "Iteration no: 443 and Loss: 64.99081420898438\n",
      "Iteration no: 444 and Loss: 64.9870376586914\n",
      "Iteration no: 445 and Loss: 64.98326873779297\n",
      "Iteration no: 446 and Loss: 64.97952270507812\n",
      "Iteration no: 447 and Loss: 64.97579956054688\n",
      "Iteration no: 448 and Loss: 64.97203826904297\n",
      "Iteration no: 449 and Loss: 64.96833801269531\n",
      "Iteration no: 450 and Loss: 64.96460723876953\n",
      "Iteration no: 451 and Loss: 64.96088409423828\n",
      "Iteration no: 452 and Loss: 64.95719146728516\n",
      "Iteration no: 453 and Loss: 64.95350646972656\n",
      "Iteration no: 454 and Loss: 64.94982147216797\n",
      "Iteration no: 455 and Loss: 64.94615173339844\n",
      "Iteration no: 456 and Loss: 64.94248962402344\n",
      "Iteration no: 457 and Loss: 64.9388427734375\n",
      "Iteration no: 458 and Loss: 64.93517303466797\n",
      "Iteration no: 459 and Loss: 64.93154907226562\n",
      "Iteration no: 460 and Loss: 64.92791748046875\n",
      "Iteration no: 461 and Loss: 64.92430114746094\n",
      "Iteration no: 462 and Loss: 64.92070007324219\n",
      "Iteration no: 463 and Loss: 64.91707611083984\n",
      "Iteration no: 464 and Loss: 64.91349029541016\n",
      "Iteration no: 465 and Loss: 64.90990447998047\n",
      "Iteration no: 466 and Loss: 64.90632629394531\n",
      "Iteration no: 467 and Loss: 64.90274810791016\n",
      "Iteration no: 468 and Loss: 64.899169921875\n",
      "Iteration no: 469 and Loss: 64.89563751220703\n",
      "Iteration no: 470 and Loss: 64.89208221435547\n",
      "Iteration no: 471 and Loss: 64.88855743408203\n",
      "Iteration no: 472 and Loss: 64.8850326538086\n",
      "Iteration no: 473 and Loss: 64.8814926147461\n",
      "Iteration no: 474 and Loss: 64.87797546386719\n",
      "Iteration no: 475 and Loss: 64.87442779541016\n",
      "Iteration no: 476 and Loss: 64.87091064453125\n",
      "Iteration no: 477 and Loss: 64.86738586425781\n",
      "Iteration no: 478 and Loss: 64.86388397216797\n",
      "Iteration no: 479 and Loss: 64.8603744506836\n",
      "Iteration no: 480 and Loss: 64.85687255859375\n",
      "Iteration no: 481 and Loss: 64.8533706665039\n",
      "Iteration no: 482 and Loss: 64.84988403320312\n",
      "Iteration no: 483 and Loss: 64.84639739990234\n",
      "Iteration no: 484 and Loss: 64.84290313720703\n",
      "Iteration no: 485 and Loss: 64.83941650390625\n",
      "Iteration no: 486 and Loss: 64.83594512939453\n",
      "Iteration no: 487 and Loss: 64.83245086669922\n",
      "Iteration no: 488 and Loss: 64.82901000976562\n",
      "Iteration no: 489 and Loss: 64.8255386352539\n",
      "Iteration no: 490 and Loss: 64.82206726074219\n",
      "Iteration no: 491 and Loss: 64.81861114501953\n",
      "Iteration no: 492 and Loss: 64.815185546875\n",
      "Iteration no: 493 and Loss: 64.81175231933594\n",
      "Iteration no: 494 and Loss: 64.80831909179688\n",
      "Iteration no: 495 and Loss: 64.80490112304688\n",
      "Iteration no: 496 and Loss: 64.8014907836914\n",
      "Iteration no: 497 and Loss: 64.79808044433594\n",
      "Iteration no: 498 and Loss: 64.794677734375\n",
      "Iteration no: 499 and Loss: 64.79125213623047\n",
      "Iteration no: 500 and Loss: 64.78788757324219\n",
      "Iteration no: 501 and Loss: 64.78451538085938\n",
      "Iteration no: 502 and Loss: 64.78114318847656\n",
      "Iteration no: 503 and Loss: 64.77776336669922\n",
      "Iteration no: 504 and Loss: 64.77442169189453\n",
      "Iteration no: 505 and Loss: 64.77107238769531\n",
      "Iteration no: 506 and Loss: 64.76770782470703\n",
      "Iteration no: 507 and Loss: 64.76434326171875\n",
      "Iteration no: 508 and Loss: 64.76099395751953\n",
      "Iteration no: 509 and Loss: 64.75762939453125\n",
      "Iteration no: 510 and Loss: 64.75428009033203\n",
      "Iteration no: 511 and Loss: 64.7509536743164\n",
      "Iteration no: 512 and Loss: 64.74760437011719\n",
      "Iteration no: 513 and Loss: 64.74427795410156\n",
      "Iteration no: 514 and Loss: 64.740966796875\n",
      "Iteration no: 515 and Loss: 64.73765563964844\n",
      "Iteration no: 516 and Loss: 64.73434448242188\n",
      "Iteration no: 517 and Loss: 64.73104858398438\n",
      "Iteration no: 518 and Loss: 64.7277603149414\n",
      "Iteration no: 519 and Loss: 64.72447967529297\n",
      "Iteration no: 520 and Loss: 64.72118377685547\n",
      "Iteration no: 521 and Loss: 64.71793365478516\n",
      "Iteration no: 522 and Loss: 64.71467590332031\n",
      "Iteration no: 523 and Loss: 64.71141052246094\n",
      "Iteration no: 524 and Loss: 64.70818328857422\n",
      "Iteration no: 525 and Loss: 64.70494842529297\n",
      "Iteration no: 526 and Loss: 64.7016830444336\n",
      "Iteration no: 527 and Loss: 64.69847106933594\n",
      "Iteration no: 528 and Loss: 64.69525146484375\n",
      "Iteration no: 529 and Loss: 64.69205474853516\n",
      "Iteration no: 530 and Loss: 64.68883514404297\n",
      "Iteration no: 531 and Loss: 64.68563842773438\n",
      "Iteration no: 532 and Loss: 64.68244171142578\n",
      "Iteration no: 533 and Loss: 64.67925262451172\n",
      "Iteration no: 534 and Loss: 64.67607879638672\n",
      "Iteration no: 535 and Loss: 64.67292022705078\n",
      "Iteration no: 536 and Loss: 64.66974639892578\n",
      "Iteration no: 537 and Loss: 64.66654205322266\n",
      "Iteration no: 538 and Loss: 64.66334533691406\n",
      "Iteration no: 539 and Loss: 64.66016387939453\n",
      "Iteration no: 540 and Loss: 64.656982421875\n",
      "Iteration no: 541 and Loss: 64.65379333496094\n",
      "Iteration no: 542 and Loss: 64.65062713623047\n",
      "Iteration no: 543 and Loss: 64.64745330810547\n",
      "Iteration no: 544 and Loss: 64.644287109375\n",
      "Iteration no: 545 and Loss: 64.64114379882812\n",
      "Iteration no: 546 and Loss: 64.63799285888672\n",
      "Iteration no: 547 and Loss: 64.63484191894531\n",
      "Iteration no: 548 and Loss: 64.63169860839844\n",
      "Iteration no: 549 and Loss: 64.62857055664062\n",
      "Iteration no: 550 and Loss: 64.62544250488281\n",
      "Iteration no: 551 and Loss: 64.6223373413086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration no: 552 and Loss: 64.61922454833984\n",
      "Iteration no: 553 and Loss: 64.61610412597656\n",
      "Iteration no: 554 and Loss: 64.61299896240234\n",
      "Iteration no: 555 and Loss: 64.60990142822266\n",
      "Iteration no: 556 and Loss: 64.60680389404297\n",
      "Iteration no: 557 and Loss: 64.60370635986328\n",
      "Iteration no: 558 and Loss: 64.60059356689453\n",
      "Iteration no: 559 and Loss: 64.5975570678711\n",
      "Iteration no: 560 and Loss: 64.59455871582031\n",
      "Iteration no: 561 and Loss: 64.5915756225586\n",
      "Iteration no: 562 and Loss: 64.58859252929688\n",
      "Iteration no: 563 and Loss: 64.58560180664062\n",
      "Iteration no: 564 and Loss: 64.58265686035156\n",
      "Iteration no: 565 and Loss: 64.5796890258789\n",
      "Iteration no: 566 and Loss: 64.57675170898438\n",
      "Iteration no: 567 and Loss: 64.57379913330078\n",
      "Iteration no: 568 and Loss: 64.57089233398438\n",
      "Iteration no: 569 and Loss: 64.56794738769531\n",
      "Iteration no: 570 and Loss: 64.56505584716797\n",
      "Iteration no: 571 and Loss: 64.5621337890625\n",
      "Iteration no: 572 and Loss: 64.55923461914062\n",
      "Iteration no: 573 and Loss: 64.55634307861328\n",
      "Iteration no: 574 and Loss: 64.553466796875\n",
      "Iteration no: 575 and Loss: 64.55058288574219\n",
      "Iteration no: 576 and Loss: 64.54771423339844\n",
      "Iteration no: 577 and Loss: 64.54486083984375\n",
      "Iteration no: 578 and Loss: 64.5419921875\n",
      "Iteration no: 579 and Loss: 64.5391616821289\n",
      "Iteration no: 580 and Loss: 64.53631591796875\n",
      "Iteration no: 581 and Loss: 64.533447265625\n",
      "Iteration no: 582 and Loss: 64.53057861328125\n",
      "Iteration no: 583 and Loss: 64.52771759033203\n",
      "Iteration no: 584 and Loss: 64.5248794555664\n",
      "Iteration no: 585 and Loss: 64.52200317382812\n",
      "Iteration no: 586 and Loss: 64.5191650390625\n",
      "Iteration no: 587 and Loss: 64.51631164550781\n",
      "Iteration no: 588 and Loss: 64.51348114013672\n",
      "Iteration no: 589 and Loss: 64.51065063476562\n",
      "Iteration no: 590 and Loss: 64.5078353881836\n",
      "Iteration no: 591 and Loss: 64.50504302978516\n",
      "Iteration no: 592 and Loss: 64.50227355957031\n",
      "Iteration no: 593 and Loss: 64.4994888305664\n",
      "Iteration no: 594 and Loss: 64.49675750732422\n",
      "Iteration no: 595 and Loss: 64.49398803710938\n",
      "Iteration no: 596 and Loss: 64.49124908447266\n",
      "Iteration no: 597 and Loss: 64.48848724365234\n",
      "Iteration no: 598 and Loss: 64.48575592041016\n",
      "Iteration no: 599 and Loss: 64.48303985595703\n",
      "Iteration no: 600 and Loss: 64.48033905029297\n",
      "Iteration no: 601 and Loss: 64.47760772705078\n",
      "Iteration no: 602 and Loss: 64.47490692138672\n",
      "Iteration no: 603 and Loss: 64.47221374511719\n",
      "Iteration no: 604 and Loss: 64.46952056884766\n",
      "Iteration no: 605 and Loss: 64.46685028076172\n",
      "Iteration no: 606 and Loss: 64.46415710449219\n",
      "Iteration no: 607 and Loss: 64.46148681640625\n",
      "Iteration no: 608 and Loss: 64.45883178710938\n",
      "Iteration no: 609 and Loss: 64.4561538696289\n",
      "Iteration no: 610 and Loss: 64.45349884033203\n",
      "Iteration no: 611 and Loss: 64.45085906982422\n",
      "Iteration no: 612 and Loss: 64.4482192993164\n",
      "Iteration no: 613 and Loss: 64.4455795288086\n",
      "Iteration no: 614 and Loss: 64.44294738769531\n",
      "Iteration no: 615 and Loss: 64.4403305053711\n",
      "Iteration no: 616 and Loss: 64.43770599365234\n",
      "Iteration no: 617 and Loss: 64.43508911132812\n",
      "Iteration no: 618 and Loss: 64.4324722290039\n",
      "Iteration no: 619 and Loss: 64.42987823486328\n",
      "Iteration no: 620 and Loss: 64.42728424072266\n",
      "Iteration no: 621 and Loss: 64.4246826171875\n",
      "Iteration no: 622 and Loss: 64.4220962524414\n",
      "Iteration no: 623 and Loss: 64.41950988769531\n",
      "Iteration no: 624 and Loss: 64.41694641113281\n",
      "Iteration no: 625 and Loss: 64.41438293457031\n",
      "Iteration no: 626 and Loss: 64.41181945800781\n",
      "Iteration no: 627 and Loss: 64.40927124023438\n",
      "Iteration no: 628 and Loss: 64.40670013427734\n",
      "Iteration no: 629 and Loss: 64.40415954589844\n",
      "Iteration no: 630 and Loss: 64.40160369873047\n",
      "Iteration no: 631 and Loss: 64.39909362792969\n",
      "Iteration no: 632 and Loss: 64.39656066894531\n",
      "Iteration no: 633 and Loss: 64.39402770996094\n",
      "Iteration no: 634 and Loss: 64.3915023803711\n",
      "Iteration no: 635 and Loss: 64.38900756835938\n",
      "Iteration no: 636 and Loss: 64.38650512695312\n",
      "Iteration no: 637 and Loss: 64.38397979736328\n",
      "Iteration no: 638 and Loss: 64.3814926147461\n",
      "Iteration no: 639 and Loss: 64.37899780273438\n",
      "Iteration no: 640 and Loss: 64.37651062011719\n",
      "Iteration no: 641 and Loss: 64.37400817871094\n",
      "Iteration no: 642 and Loss: 64.37142944335938\n",
      "Iteration no: 643 and Loss: 64.36885070800781\n",
      "Iteration no: 644 and Loss: 64.36627960205078\n",
      "Iteration no: 645 and Loss: 64.36369323730469\n",
      "Iteration no: 646 and Loss: 64.3611068725586\n",
      "Iteration no: 647 and Loss: 64.35851287841797\n",
      "Iteration no: 648 and Loss: 64.35591888427734\n",
      "Iteration no: 649 and Loss: 64.35330963134766\n",
      "Iteration no: 650 and Loss: 64.3507080078125\n",
      "Iteration no: 651 and Loss: 64.34810638427734\n",
      "Iteration no: 652 and Loss: 64.34547424316406\n",
      "Iteration no: 653 and Loss: 64.34288024902344\n",
      "Iteration no: 654 and Loss: 64.34027862548828\n",
      "Iteration no: 655 and Loss: 64.33766174316406\n",
      "Iteration no: 656 and Loss: 64.33506774902344\n",
      "Iteration no: 657 and Loss: 64.33244323730469\n",
      "Iteration no: 658 and Loss: 64.32984161376953\n",
      "Iteration no: 659 and Loss: 64.3272476196289\n",
      "Iteration no: 660 and Loss: 64.32466888427734\n",
      "Iteration no: 661 and Loss: 64.32207489013672\n",
      "Iteration no: 662 and Loss: 64.3194808959961\n",
      "Iteration no: 663 and Loss: 64.31689453125\n",
      "Iteration no: 664 and Loss: 64.3143081665039\n",
      "Iteration no: 665 and Loss: 64.31172943115234\n",
      "Iteration no: 666 and Loss: 64.30916595458984\n",
      "Iteration no: 667 and Loss: 64.30660247802734\n",
      "Iteration no: 668 and Loss: 64.30402374267578\n",
      "Iteration no: 669 and Loss: 64.30147552490234\n",
      "Iteration no: 670 and Loss: 64.29891204833984\n",
      "Iteration no: 671 and Loss: 64.29635620117188\n",
      "Iteration no: 672 and Loss: 64.29380798339844\n",
      "Iteration no: 673 and Loss: 64.29127502441406\n",
      "Iteration no: 674 and Loss: 64.28877258300781\n",
      "Iteration no: 675 and Loss: 64.28621673583984\n",
      "Iteration no: 676 and Loss: 64.28369903564453\n",
      "Iteration no: 677 and Loss: 64.28116607666016\n",
      "Iteration no: 678 and Loss: 64.27867889404297\n",
      "Iteration no: 679 and Loss: 64.27616882324219\n",
      "Iteration no: 680 and Loss: 64.27365112304688\n",
      "Iteration no: 681 and Loss: 64.27111053466797\n",
      "Iteration no: 682 and Loss: 64.26858520507812\n",
      "Iteration no: 683 and Loss: 64.26602935791016\n",
      "Iteration no: 684 and Loss: 64.26348114013672\n",
      "Iteration no: 685 and Loss: 64.26094055175781\n",
      "Iteration no: 686 and Loss: 64.2583999633789\n",
      "Iteration no: 687 and Loss: 64.25586700439453\n",
      "Iteration no: 688 and Loss: 64.25334930419922\n",
      "Iteration no: 689 and Loss: 64.25078582763672\n",
      "Iteration no: 690 and Loss: 64.24828338623047\n",
      "Iteration no: 691 and Loss: 64.24574279785156\n",
      "Iteration no: 692 and Loss: 64.24320220947266\n",
      "Iteration no: 693 and Loss: 64.24069213867188\n",
      "Iteration no: 694 and Loss: 64.23816680908203\n",
      "Iteration no: 695 and Loss: 64.23565673828125\n",
      "Iteration no: 696 and Loss: 64.233154296875\n",
      "Iteration no: 697 and Loss: 64.23063659667969\n",
      "Iteration no: 698 and Loss: 64.22814178466797\n",
      "Iteration no: 699 and Loss: 64.22563934326172\n",
      "Iteration no: 700 and Loss: 64.22314453125\n",
      "Iteration no: 701 and Loss: 64.22066497802734\n",
      "Iteration no: 702 and Loss: 64.21818542480469\n",
      "Iteration no: 703 and Loss: 64.2156982421875\n",
      "Iteration no: 704 and Loss: 64.21321868896484\n",
      "Iteration no: 705 and Loss: 64.21076202392578\n",
      "Iteration no: 706 and Loss: 64.20833587646484\n",
      "Iteration no: 707 and Loss: 64.20592498779297\n",
      "Iteration no: 708 and Loss: 64.2035140991211\n",
      "Iteration no: 709 and Loss: 64.20110321044922\n",
      "Iteration no: 710 and Loss: 64.19869995117188\n",
      "Iteration no: 711 and Loss: 64.19632720947266\n",
      "Iteration no: 712 and Loss: 64.19393157958984\n",
      "Iteration no: 713 and Loss: 64.19153594970703\n",
      "Iteration no: 714 and Loss: 64.1891860961914\n",
      "Iteration no: 715 and Loss: 64.18685913085938\n",
      "Iteration no: 716 and Loss: 64.18450164794922\n",
      "Iteration no: 717 and Loss: 64.18221282958984\n",
      "Iteration no: 718 and Loss: 64.17987060546875\n",
      "Iteration no: 719 and Loss: 64.17757415771484\n",
      "Iteration no: 720 and Loss: 64.17526245117188\n",
      "Iteration no: 721 and Loss: 64.17305755615234\n",
      "Iteration no: 722 and Loss: 64.17089080810547\n",
      "Iteration no: 723 and Loss: 64.1687240600586\n",
      "Iteration no: 724 and Loss: 64.16654968261719\n",
      "Iteration no: 725 and Loss: 64.16439056396484\n",
      "Iteration no: 726 and Loss: 64.1622543334961\n",
      "Iteration no: 727 and Loss: 64.16011047363281\n",
      "Iteration no: 728 and Loss: 64.15797424316406\n",
      "Iteration no: 729 and Loss: 64.15582275390625\n",
      "Iteration no: 730 and Loss: 64.1536865234375\n",
      "Iteration no: 731 and Loss: 64.15157318115234\n",
      "Iteration no: 732 and Loss: 64.14945220947266\n",
      "Iteration no: 733 and Loss: 64.14734649658203\n",
      "Iteration no: 734 and Loss: 64.14523315429688\n",
      "Iteration no: 735 and Loss: 64.14311981201172\n",
      "Iteration no: 736 and Loss: 64.1410140991211\n",
      "Iteration no: 737 and Loss: 64.13890075683594\n",
      "Iteration no: 738 and Loss: 64.13677978515625\n",
      "Iteration no: 739 and Loss: 64.13465118408203\n",
      "Iteration no: 740 and Loss: 64.13251495361328\n",
      "Iteration no: 741 and Loss: 64.1303939819336\n",
      "Iteration no: 742 and Loss: 64.12828826904297\n",
      "Iteration no: 743 and Loss: 64.12615966796875\n",
      "Iteration no: 744 and Loss: 64.1240463256836\n",
      "Iteration no: 745 and Loss: 64.1219482421875\n",
      "Iteration no: 746 and Loss: 64.11981964111328\n",
      "Iteration no: 747 and Loss: 64.11772155761719\n",
      "Iteration no: 748 and Loss: 64.1156234741211\n",
      "Iteration no: 749 and Loss: 64.11351776123047\n",
      "Iteration no: 750 and Loss: 64.1114273071289\n",
      "Iteration no: 751 and Loss: 64.10931396484375\n",
      "Iteration no: 752 and Loss: 64.10720825195312\n",
      "Iteration no: 753 and Loss: 64.10508728027344\n",
      "Iteration no: 754 and Loss: 64.10299682617188\n",
      "Iteration no: 755 and Loss: 64.10086822509766\n",
      "Iteration no: 756 and Loss: 64.09877014160156\n",
      "Iteration no: 757 and Loss: 64.09664916992188\n",
      "Iteration no: 758 and Loss: 64.09452819824219\n",
      "Iteration no: 759 and Loss: 64.09242248535156\n",
      "Iteration no: 760 and Loss: 64.09031677246094\n",
      "Iteration no: 761 and Loss: 64.08820343017578\n",
      "Iteration no: 762 and Loss: 64.08611297607422\n",
      "Iteration no: 763 and Loss: 64.08399200439453\n",
      "Iteration no: 764 and Loss: 64.0819091796875\n",
      "Iteration no: 765 and Loss: 64.07981872558594\n",
      "Iteration no: 766 and Loss: 64.07772827148438\n",
      "Iteration no: 767 and Loss: 64.07563781738281\n",
      "Iteration no: 768 and Loss: 64.07354736328125\n",
      "Iteration no: 769 and Loss: 64.07147216796875\n",
      "Iteration no: 770 and Loss: 64.06938171386719\n",
      "Iteration no: 771 and Loss: 64.06730651855469\n",
      "Iteration no: 772 and Loss: 64.06523132324219\n",
      "Iteration no: 773 and Loss: 64.06317901611328\n",
      "Iteration no: 774 and Loss: 64.06111145019531\n",
      "Iteration no: 775 and Loss: 64.05904388427734\n",
      "Iteration no: 776 and Loss: 64.05699157714844\n",
      "Iteration no: 777 and Loss: 64.054931640625\n",
      "Iteration no: 778 and Loss: 64.05290985107422\n",
      "Iteration no: 779 and Loss: 64.05089569091797\n",
      "Iteration no: 780 and Loss: 64.0488510131836\n",
      "Iteration no: 781 and Loss: 64.04681396484375\n",
      "Iteration no: 782 and Loss: 64.0447769165039\n",
      "Iteration no: 783 and Loss: 64.0427474975586\n",
      "Iteration no: 784 and Loss: 64.04074096679688\n",
      "Iteration no: 785 and Loss: 64.03872680664062\n",
      "Iteration no: 786 and Loss: 64.03671264648438\n",
      "Iteration no: 787 and Loss: 64.03471374511719\n",
      "Iteration no: 788 and Loss: 64.03271484375\n",
      "Iteration no: 789 and Loss: 64.03071594238281\n",
      "Iteration no: 790 and Loss: 64.02871704101562\n",
      "Iteration no: 791 and Loss: 64.02672576904297\n",
      "Iteration no: 792 and Loss: 64.02476501464844\n",
      "Iteration no: 793 and Loss: 64.02277374267578\n",
      "Iteration no: 794 and Loss: 64.02074432373047\n",
      "Iteration no: 795 and Loss: 64.01870727539062\n",
      "Iteration no: 796 and Loss: 64.01665496826172\n",
      "Iteration no: 797 and Loss: 64.01461029052734\n",
      "Iteration no: 798 and Loss: 64.01253509521484\n",
      "Iteration no: 799 and Loss: 64.01049041748047\n",
      "Iteration no: 800 and Loss: 64.00843811035156\n",
      "Iteration no: 801 and Loss: 64.00638580322266\n",
      "Iteration no: 802 and Loss: 64.00434112548828\n",
      "Iteration no: 803 and Loss: 64.00228881835938\n",
      "Iteration no: 804 and Loss: 64.00023651123047\n",
      "Iteration no: 805 and Loss: 63.998191833496094\n",
      "Iteration no: 806 and Loss: 63.99615478515625\n",
      "Iteration no: 807 and Loss: 63.99410629272461\n",
      "Iteration no: 808 and Loss: 63.99205017089844\n",
      "Iteration no: 809 and Loss: 63.990020751953125\n",
      "Iteration no: 810 and Loss: 63.98798751831055\n",
      "Iteration no: 811 and Loss: 63.985958099365234\n",
      "Iteration no: 812 and Loss: 63.983970642089844\n",
      "Iteration no: 813 and Loss: 63.98198318481445\n",
      "Iteration no: 814 and Loss: 63.97998046875\n",
      "Iteration no: 815 and Loss: 63.978031158447266\n",
      "Iteration no: 816 and Loss: 63.97604751586914\n",
      "Iteration no: 817 and Loss: 63.97410202026367\n",
      "Iteration no: 818 and Loss: 63.97214126586914\n",
      "Iteration no: 819 and Loss: 63.97018814086914\n",
      "Iteration no: 820 and Loss: 63.96823501586914\n",
      "Iteration no: 821 and Loss: 63.966278076171875\n",
      "Iteration no: 822 and Loss: 63.964351654052734\n",
      "Iteration no: 823 and Loss: 63.96241760253906\n",
      "Iteration no: 824 and Loss: 63.96049880981445\n",
      "Iteration no: 825 and Loss: 63.95856857299805\n",
      "Iteration no: 826 and Loss: 63.956642150878906\n",
      "Iteration no: 827 and Loss: 63.95475769042969\n",
      "Iteration no: 828 and Loss: 63.95283889770508\n",
      "Iteration no: 829 and Loss: 63.95094299316406\n",
      "Iteration no: 830 and Loss: 63.94905090332031\n",
      "Iteration no: 831 and Loss: 63.9471435546875\n",
      "Iteration no: 832 and Loss: 63.94525909423828\n",
      "Iteration no: 833 and Loss: 63.94337463378906\n",
      "Iteration no: 834 and Loss: 63.941490173339844\n",
      "Iteration no: 835 and Loss: 63.93961715698242\n",
      "Iteration no: 836 and Loss: 63.93772506713867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration no: 837 and Loss: 63.93586730957031\n",
      "Iteration no: 838 and Loss: 63.93400573730469\n",
      "Iteration no: 839 and Loss: 63.932132720947266\n",
      "Iteration no: 840 and Loss: 63.930274963378906\n",
      "Iteration no: 841 and Loss: 63.92842102050781\n",
      "Iteration no: 842 and Loss: 63.926570892333984\n",
      "Iteration no: 843 and Loss: 63.924720764160156\n",
      "Iteration no: 844 and Loss: 63.92286682128906\n",
      "Iteration no: 845 and Loss: 63.92104721069336\n",
      "Iteration no: 846 and Loss: 63.91919708251953\n",
      "Iteration no: 847 and Loss: 63.91738510131836\n",
      "Iteration no: 848 and Loss: 63.915565490722656\n",
      "Iteration no: 849 and Loss: 63.913726806640625\n",
      "Iteration no: 850 and Loss: 63.91193389892578\n",
      "Iteration no: 851 and Loss: 63.91012191772461\n",
      "Iteration no: 852 and Loss: 63.90830612182617\n",
      "Iteration no: 853 and Loss: 63.90650939941406\n",
      "Iteration no: 854 and Loss: 63.90471267700195\n",
      "Iteration no: 855 and Loss: 63.90290832519531\n",
      "Iteration no: 856 and Loss: 63.90110397338867\n",
      "Iteration no: 857 and Loss: 63.89933395385742\n",
      "Iteration no: 858 and Loss: 63.89752960205078\n",
      "Iteration no: 859 and Loss: 63.89576721191406\n",
      "Iteration no: 860 and Loss: 63.89399337768555\n",
      "Iteration no: 861 and Loss: 63.89220428466797\n",
      "Iteration no: 862 and Loss: 63.89044952392578\n",
      "Iteration no: 863 and Loss: 63.88874816894531\n",
      "Iteration no: 864 and Loss: 63.88706970214844\n",
      "Iteration no: 865 and Loss: 63.88541030883789\n",
      "Iteration no: 866 and Loss: 63.88375473022461\n",
      "Iteration no: 867 and Loss: 63.8820915222168\n",
      "Iteration no: 868 and Loss: 63.880462646484375\n",
      "Iteration no: 869 and Loss: 63.878814697265625\n",
      "Iteration no: 870 and Loss: 63.87716293334961\n",
      "Iteration no: 871 and Loss: 63.87553787231445\n",
      "Iteration no: 872 and Loss: 63.87392044067383\n",
      "Iteration no: 873 and Loss: 63.872291564941406\n",
      "Iteration no: 874 and Loss: 63.870689392089844\n",
      "Iteration no: 875 and Loss: 63.869075775146484\n",
      "Iteration no: 876 and Loss: 63.8675651550293\n",
      "Iteration no: 877 and Loss: 63.86610412597656\n",
      "Iteration no: 878 and Loss: 63.86467742919922\n",
      "Iteration no: 879 and Loss: 63.86323547363281\n",
      "Iteration no: 880 and Loss: 63.861812591552734\n",
      "Iteration no: 881 and Loss: 63.86037826538086\n",
      "Iteration no: 882 and Loss: 63.85895538330078\n",
      "Iteration no: 883 and Loss: 63.857547760009766\n",
      "Iteration no: 884 and Loss: 63.856136322021484\n",
      "Iteration no: 885 and Loss: 63.85474395751953\n",
      "Iteration no: 886 and Loss: 63.85335922241211\n",
      "Iteration no: 887 and Loss: 63.85197448730469\n",
      "Iteration no: 888 and Loss: 63.850582122802734\n",
      "Iteration no: 889 and Loss: 63.849205017089844\n",
      "Iteration no: 890 and Loss: 63.847808837890625\n",
      "Iteration no: 891 and Loss: 63.84645080566406\n",
      "Iteration no: 892 and Loss: 63.84506607055664\n",
      "Iteration no: 893 and Loss: 63.84369659423828\n",
      "Iteration no: 894 and Loss: 63.842308044433594\n",
      "Iteration no: 895 and Loss: 63.84090805053711\n",
      "Iteration no: 896 and Loss: 63.83952331542969\n",
      "Iteration no: 897 and Loss: 63.838134765625\n",
      "Iteration no: 898 and Loss: 63.83673095703125\n",
      "Iteration no: 899 and Loss: 63.8353385925293\n",
      "Iteration no: 900 and Loss: 63.833946228027344\n",
      "Iteration no: 901 and Loss: 63.832584381103516\n",
      "Iteration no: 902 and Loss: 63.83123016357422\n",
      "Iteration no: 903 and Loss: 63.82986831665039\n",
      "Iteration no: 904 and Loss: 63.82853698730469\n",
      "Iteration no: 905 and Loss: 63.82719421386719\n",
      "Iteration no: 906 and Loss: 63.825862884521484\n",
      "Iteration no: 907 and Loss: 63.824546813964844\n",
      "Iteration no: 908 and Loss: 63.8232307434082\n",
      "Iteration no: 909 and Loss: 63.821903228759766\n",
      "Iteration no: 910 and Loss: 63.820579528808594\n",
      "Iteration no: 911 and Loss: 63.819278717041016\n",
      "Iteration no: 912 and Loss: 63.817955017089844\n",
      "Iteration no: 913 and Loss: 63.816654205322266\n",
      "Iteration no: 914 and Loss: 63.81534957885742\n",
      "Iteration no: 915 and Loss: 63.814048767089844\n",
      "Iteration no: 916 and Loss: 63.8127555847168\n",
      "Iteration no: 917 and Loss: 63.811458587646484\n",
      "Iteration no: 918 and Loss: 63.81016540527344\n",
      "Iteration no: 919 and Loss: 63.80887222290039\n",
      "Iteration no: 920 and Loss: 63.80759811401367\n",
      "Iteration no: 921 and Loss: 63.80630874633789\n",
      "Iteration no: 922 and Loss: 63.805023193359375\n",
      "Iteration no: 923 and Loss: 63.80375671386719\n",
      "Iteration no: 924 and Loss: 63.802494049072266\n",
      "Iteration no: 925 and Loss: 63.801246643066406\n",
      "Iteration no: 926 and Loss: 63.79999542236328\n",
      "Iteration no: 927 and Loss: 63.798744201660156\n",
      "Iteration no: 928 and Loss: 63.79751205444336\n",
      "Iteration no: 929 and Loss: 63.79625701904297\n",
      "Iteration no: 930 and Loss: 63.795040130615234\n",
      "Iteration no: 931 and Loss: 63.79380798339844\n",
      "Iteration no: 932 and Loss: 63.79257583618164\n",
      "Iteration no: 933 and Loss: 63.79134750366211\n",
      "Iteration no: 934 and Loss: 63.79012680053711\n",
      "Iteration no: 935 and Loss: 63.788902282714844\n",
      "Iteration no: 936 and Loss: 63.787681579589844\n",
      "Iteration no: 937 and Loss: 63.78645706176758\n",
      "Iteration no: 938 and Loss: 63.785240173339844\n",
      "Iteration no: 939 and Loss: 63.784034729003906\n",
      "Iteration no: 940 and Loss: 63.7828254699707\n",
      "Iteration no: 941 and Loss: 63.78163146972656\n",
      "Iteration no: 942 and Loss: 63.78041076660156\n",
      "Iteration no: 943 and Loss: 63.77922058105469\n",
      "Iteration no: 944 and Loss: 63.77800369262695\n",
      "Iteration no: 945 and Loss: 63.77682113647461\n",
      "Iteration no: 946 and Loss: 63.77564239501953\n",
      "Iteration no: 947 and Loss: 63.77445983886719\n",
      "Iteration no: 948 and Loss: 63.773250579833984\n",
      "Iteration no: 949 and Loss: 63.7720947265625\n",
      "Iteration no: 950 and Loss: 63.77091598510742\n",
      "Iteration no: 951 and Loss: 63.769744873046875\n",
      "Iteration no: 952 and Loss: 63.76856231689453\n",
      "Iteration no: 953 and Loss: 63.76740264892578\n",
      "Iteration no: 954 and Loss: 63.7662353515625\n",
      "Iteration no: 955 and Loss: 63.765079498291016\n",
      "Iteration no: 956 and Loss: 63.763919830322266\n",
      "Iteration no: 957 and Loss: 63.76274490356445\n",
      "Iteration no: 958 and Loss: 63.761592864990234\n",
      "Iteration no: 959 and Loss: 63.76044464111328\n",
      "Iteration no: 960 and Loss: 63.75929641723633\n",
      "Iteration no: 961 and Loss: 63.75812530517578\n",
      "Iteration no: 962 and Loss: 63.756980895996094\n",
      "Iteration no: 963 and Loss: 63.755836486816406\n",
      "Iteration no: 964 and Loss: 63.754676818847656\n",
      "Iteration no: 965 and Loss: 63.75353240966797\n",
      "Iteration no: 966 and Loss: 63.75236892700195\n",
      "Iteration no: 967 and Loss: 63.751216888427734\n",
      "Iteration no: 968 and Loss: 63.750064849853516\n",
      "Iteration no: 969 and Loss: 63.74892044067383\n",
      "Iteration no: 970 and Loss: 63.74777603149414\n",
      "Iteration no: 971 and Loss: 63.74662399291992\n",
      "Iteration no: 972 and Loss: 63.74547576904297\n",
      "Iteration no: 973 and Loss: 63.744354248046875\n",
      "Iteration no: 974 and Loss: 63.743194580078125\n",
      "Iteration no: 975 and Loss: 63.742061614990234\n",
      "Iteration no: 976 and Loss: 63.74092483520508\n",
      "Iteration no: 977 and Loss: 63.739784240722656\n",
      "Iteration no: 978 and Loss: 63.7386589050293\n",
      "Iteration no: 979 and Loss: 63.737525939941406\n",
      "Iteration no: 980 and Loss: 63.736385345458984\n",
      "Iteration no: 981 and Loss: 63.73527145385742\n",
      "Iteration no: 982 and Loss: 63.734153747558594\n",
      "Iteration no: 983 and Loss: 63.73300552368164\n",
      "Iteration no: 984 and Loss: 63.731876373291016\n",
      "Iteration no: 985 and Loss: 63.730770111083984\n",
      "Iteration no: 986 and Loss: 63.72966384887695\n",
      "Iteration no: 987 and Loss: 63.728546142578125\n",
      "Iteration no: 988 and Loss: 63.727420806884766\n",
      "Iteration no: 989 and Loss: 63.72629928588867\n",
      "Iteration no: 990 and Loss: 63.72518539428711\n",
      "Iteration no: 991 and Loss: 63.72404479980469\n",
      "Iteration no: 992 and Loss: 63.7229118347168\n",
      "Iteration no: 993 and Loss: 63.72177505493164\n",
      "Iteration no: 994 and Loss: 63.72064971923828\n",
      "Iteration no: 995 and Loss: 63.71952438354492\n",
      "Iteration no: 996 and Loss: 63.71839904785156\n",
      "Iteration no: 997 and Loss: 63.71726989746094\n",
      "Iteration no: 998 and Loss: 63.71614456176758\n",
      "Iteration no: 999 and Loss: 63.71502685546875\n",
      "Iteration no: 1000 and Loss: 63.71390151977539\n",
      "Iteration no: 1001 and Loss: 63.71276092529297\n",
      "Iteration no: 1002 and Loss: 63.711666107177734\n",
      "Iteration no: 1003 and Loss: 63.710533142089844\n",
      "Iteration no: 1004 and Loss: 63.70940017700195\n",
      "Iteration no: 1005 and Loss: 63.708290100097656\n",
      "Iteration no: 1006 and Loss: 63.70716857910156\n",
      "Iteration no: 1007 and Loss: 63.706058502197266\n",
      "Iteration no: 1008 and Loss: 63.70492935180664\n",
      "Iteration no: 1009 and Loss: 63.70380783081055\n",
      "Iteration no: 1010 and Loss: 63.70269775390625\n",
      "Iteration no: 1011 and Loss: 63.70159149169922\n",
      "Iteration no: 1012 and Loss: 63.70048141479492\n",
      "Iteration no: 1013 and Loss: 63.69935607910156\n",
      "Iteration no: 1014 and Loss: 63.69824981689453\n",
      "Iteration no: 1015 and Loss: 63.69713592529297\n",
      "Iteration no: 1016 and Loss: 63.69601821899414\n",
      "Iteration no: 1017 and Loss: 63.6949462890625\n",
      "Iteration no: 1018 and Loss: 63.693843841552734\n",
      "Iteration no: 1019 and Loss: 63.692771911621094\n",
      "Iteration no: 1020 and Loss: 63.69167709350586\n",
      "Iteration no: 1021 and Loss: 63.69059371948242\n",
      "Iteration no: 1022 and Loss: 63.68952178955078\n",
      "Iteration no: 1023 and Loss: 63.688438415527344\n",
      "Iteration no: 1024 and Loss: 63.687347412109375\n",
      "Iteration no: 1025 and Loss: 63.686283111572266\n",
      "Iteration no: 1026 and Loss: 63.685211181640625\n",
      "Iteration no: 1027 and Loss: 63.68412780761719\n",
      "Iteration no: 1028 and Loss: 63.68305206298828\n",
      "Iteration no: 1029 and Loss: 63.6820068359375\n",
      "Iteration no: 1030 and Loss: 63.680931091308594\n",
      "Iteration no: 1031 and Loss: 63.67985916137695\n",
      "Iteration no: 1032 and Loss: 63.678794860839844\n",
      "Iteration no: 1033 and Loss: 63.6777458190918\n",
      "Iteration no: 1034 and Loss: 63.67668533325195\n",
      "Iteration no: 1035 and Loss: 63.67562484741211\n",
      "Iteration no: 1036 and Loss: 63.674560546875\n",
      "Iteration no: 1037 and Loss: 63.673500061035156\n",
      "Iteration no: 1038 and Loss: 63.6724739074707\n",
      "Iteration no: 1039 and Loss: 63.67140579223633\n",
      "Iteration no: 1040 and Loss: 63.67037582397461\n",
      "Iteration no: 1041 and Loss: 63.66935729980469\n",
      "Iteration no: 1042 and Loss: 63.668331146240234\n",
      "Iteration no: 1043 and Loss: 63.66730499267578\n",
      "Iteration no: 1044 and Loss: 63.66627502441406\n",
      "Iteration no: 1045 and Loss: 63.66525650024414\n",
      "Iteration no: 1046 and Loss: 63.66424560546875\n",
      "Iteration no: 1047 and Loss: 63.6632080078125\n",
      "Iteration no: 1048 and Loss: 63.6622200012207\n",
      "Iteration no: 1049 and Loss: 63.66120147705078\n",
      "Iteration no: 1050 and Loss: 63.66019058227539\n",
      "Iteration no: 1051 and Loss: 63.659175872802734\n",
      "Iteration no: 1052 and Loss: 63.658180236816406\n",
      "Iteration no: 1053 and Loss: 63.657161712646484\n",
      "Iteration no: 1054 and Loss: 63.656150817871094\n",
      "Iteration no: 1055 and Loss: 63.6551513671875\n",
      "Iteration no: 1056 and Loss: 63.654151916503906\n",
      "Iteration no: 1057 and Loss: 63.65314865112305\n",
      "Iteration no: 1058 and Loss: 63.652156829833984\n",
      "Iteration no: 1059 and Loss: 63.65116882324219\n",
      "Iteration no: 1060 and Loss: 63.650169372558594\n",
      "Iteration no: 1061 and Loss: 63.649173736572266\n",
      "Iteration no: 1062 and Loss: 63.648189544677734\n",
      "Iteration no: 1063 and Loss: 63.64720916748047\n",
      "Iteration no: 1064 and Loss: 63.64622497558594\n",
      "Iteration no: 1065 and Loss: 63.645240783691406\n",
      "Iteration no: 1066 and Loss: 63.64425277709961\n",
      "Iteration no: 1067 and Loss: 63.643287658691406\n",
      "Iteration no: 1068 and Loss: 63.642330169677734\n",
      "Iteration no: 1069 and Loss: 63.641380310058594\n",
      "Iteration no: 1070 and Loss: 63.64041519165039\n",
      "Iteration no: 1071 and Loss: 63.639469146728516\n",
      "Iteration no: 1072 and Loss: 63.638519287109375\n",
      "Iteration no: 1073 and Loss: 63.637569427490234\n",
      "Iteration no: 1074 and Loss: 63.63662338256836\n",
      "Iteration no: 1075 and Loss: 63.63566970825195\n",
      "Iteration no: 1076 and Loss: 63.634735107421875\n",
      "Iteration no: 1077 and Loss: 63.63379669189453\n",
      "Iteration no: 1078 and Loss: 63.63285446166992\n",
      "Iteration no: 1079 and Loss: 63.63190460205078\n",
      "Iteration no: 1080 and Loss: 63.63098907470703\n",
      "Iteration no: 1081 and Loss: 63.63005447387695\n",
      "Iteration no: 1082 and Loss: 63.629119873046875\n",
      "Iteration no: 1083 and Loss: 63.628196716308594\n",
      "Iteration no: 1084 and Loss: 63.627254486083984\n",
      "Iteration no: 1085 and Loss: 63.62632369995117\n",
      "Iteration no: 1086 and Loss: 63.62541198730469\n",
      "Iteration no: 1087 and Loss: 63.62449645996094\n",
      "Iteration no: 1088 and Loss: 63.62356948852539\n",
      "Iteration no: 1089 and Loss: 63.622623443603516\n",
      "Iteration no: 1090 and Loss: 63.62163162231445\n",
      "Iteration no: 1091 and Loss: 63.62063980102539\n",
      "Iteration no: 1092 and Loss: 63.61962127685547\n",
      "Iteration no: 1093 and Loss: 63.61862564086914\n",
      "Iteration no: 1094 and Loss: 63.61759567260742\n",
      "Iteration no: 1095 and Loss: 63.616580963134766\n",
      "Iteration no: 1096 and Loss: 63.61552429199219\n",
      "Iteration no: 1097 and Loss: 63.614505767822266\n",
      "Iteration no: 1098 and Loss: 63.61347961425781\n",
      "Iteration no: 1099 and Loss: 63.61240768432617\n",
      "Iteration no: 1100 and Loss: 63.61138153076172\n",
      "Iteration no: 1101 and Loss: 63.61033630371094\n",
      "Iteration no: 1102 and Loss: 63.609256744384766\n",
      "Iteration no: 1103 and Loss: 63.608184814453125\n",
      "Iteration no: 1104 and Loss: 63.607120513916016\n",
      "Iteration no: 1105 and Loss: 63.60605239868164\n",
      "Iteration no: 1106 and Loss: 63.604957580566406\n",
      "Iteration no: 1107 and Loss: 63.6038703918457\n",
      "Iteration no: 1108 and Loss: 63.60274887084961\n",
      "Iteration no: 1109 and Loss: 63.601646423339844\n",
      "Iteration no: 1110 and Loss: 63.60053253173828\n",
      "Iteration no: 1111 and Loss: 63.59941101074219\n",
      "Iteration no: 1112 and Loss: 63.59830093383789\n",
      "Iteration no: 1113 and Loss: 63.59716033935547\n",
      "Iteration no: 1114 and Loss: 63.59605026245117\n",
      "Iteration no: 1115 and Loss: 63.59490203857422\n",
      "Iteration no: 1116 and Loss: 63.59376525878906\n",
      "Iteration no: 1117 and Loss: 63.592620849609375\n",
      "Iteration no: 1118 and Loss: 63.59148025512695\n",
      "Iteration no: 1119 and Loss: 63.590354919433594\n",
      "Iteration no: 1120 and Loss: 63.58919906616211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration no: 1121 and Loss: 63.588069915771484\n",
      "Iteration no: 1122 and Loss: 63.58693313598633\n",
      "Iteration no: 1123 and Loss: 63.58578872680664\n",
      "Iteration no: 1124 and Loss: 63.58463668823242\n",
      "Iteration no: 1125 and Loss: 63.58349609375\n",
      "Iteration no: 1126 and Loss: 63.58235549926758\n",
      "Iteration no: 1127 and Loss: 63.58120346069336\n",
      "Iteration no: 1128 and Loss: 63.58007049560547\n",
      "Iteration no: 1129 and Loss: 63.578922271728516\n",
      "Iteration no: 1130 and Loss: 63.57779312133789\n",
      "Iteration no: 1131 and Loss: 63.57664489746094\n",
      "Iteration no: 1132 and Loss: 63.57552719116211\n",
      "Iteration no: 1133 and Loss: 63.57439041137695\n",
      "Iteration no: 1134 and Loss: 63.573265075683594\n",
      "Iteration no: 1135 and Loss: 63.57212829589844\n",
      "Iteration no: 1136 and Loss: 63.571006774902344\n",
      "Iteration no: 1137 and Loss: 63.56987762451172\n",
      "Iteration no: 1138 and Loss: 63.56875991821289\n",
      "Iteration no: 1139 and Loss: 63.567626953125\n",
      "Iteration no: 1140 and Loss: 63.5665168762207\n",
      "Iteration no: 1141 and Loss: 63.56539535522461\n",
      "Iteration no: 1142 and Loss: 63.56433868408203\n",
      "Iteration no: 1143 and Loss: 63.563377380371094\n",
      "Iteration no: 1144 and Loss: 63.56241226196289\n",
      "Iteration no: 1145 and Loss: 63.561458587646484\n",
      "Iteration no: 1146 and Loss: 63.56050491333008\n",
      "Iteration no: 1147 and Loss: 63.55957794189453\n",
      "Iteration no: 1148 and Loss: 63.55863571166992\n",
      "Iteration no: 1149 and Loss: 63.557701110839844\n",
      "Iteration no: 1150 and Loss: 63.5567741394043\n",
      "Iteration no: 1151 and Loss: 63.555843353271484\n",
      "Iteration no: 1152 and Loss: 63.5549201965332\n",
      "Iteration no: 1153 and Loss: 63.55400466918945\n",
      "Iteration no: 1154 and Loss: 63.553096771240234\n",
      "Iteration no: 1155 and Loss: 63.55216598510742\n",
      "Iteration no: 1156 and Loss: 63.551246643066406\n",
      "Iteration no: 1157 and Loss: 63.55034637451172\n",
      "Iteration no: 1158 and Loss: 63.54945755004883\n",
      "Iteration no: 1159 and Loss: 63.54854202270508\n",
      "Iteration no: 1160 and Loss: 63.54762649536133\n",
      "Iteration no: 1161 and Loss: 63.5467529296875\n",
      "Iteration no: 1162 and Loss: 63.54584884643555\n",
      "Iteration no: 1163 and Loss: 63.54492950439453\n",
      "Iteration no: 1164 and Loss: 63.54404830932617\n",
      "Iteration no: 1165 and Loss: 63.543155670166016\n",
      "Iteration no: 1166 and Loss: 63.54225540161133\n",
      "Iteration no: 1167 and Loss: 63.54134750366211\n",
      "Iteration no: 1168 and Loss: 63.54042053222656\n",
      "Iteration no: 1169 and Loss: 63.53948974609375\n",
      "Iteration no: 1170 and Loss: 63.5385856628418\n",
      "Iteration no: 1171 and Loss: 63.53765869140625\n",
      "Iteration no: 1172 and Loss: 63.53672409057617\n",
      "Iteration no: 1173 and Loss: 63.53580093383789\n",
      "Iteration no: 1174 and Loss: 63.53488540649414\n",
      "Iteration no: 1175 and Loss: 63.5339469909668\n",
      "Iteration no: 1176 and Loss: 63.53303146362305\n",
      "Iteration no: 1177 and Loss: 63.53209686279297\n",
      "Iteration no: 1178 and Loss: 63.53116989135742\n",
      "Iteration no: 1179 and Loss: 63.53024673461914\n",
      "Iteration no: 1180 and Loss: 63.52933120727539\n",
      "Iteration no: 1181 and Loss: 63.52838134765625\n",
      "Iteration no: 1182 and Loss: 63.52742385864258\n",
      "Iteration no: 1183 and Loss: 63.52648162841797\n",
      "Iteration no: 1184 and Loss: 63.525516510009766\n",
      "Iteration no: 1185 and Loss: 63.524574279785156\n",
      "Iteration no: 1186 and Loss: 63.52362823486328\n",
      "Iteration no: 1187 and Loss: 63.52265167236328\n",
      "Iteration no: 1188 and Loss: 63.52170181274414\n",
      "Iteration no: 1189 and Loss: 63.520721435546875\n",
      "Iteration no: 1190 and Loss: 63.519779205322266\n",
      "Iteration no: 1191 and Loss: 63.5188102722168\n",
      "Iteration no: 1192 and Loss: 63.51784896850586\n",
      "Iteration no: 1193 and Loss: 63.516902923583984\n",
      "Iteration no: 1194 and Loss: 63.51593780517578\n",
      "Iteration no: 1195 and Loss: 63.51497268676758\n",
      "Iteration no: 1196 and Loss: 63.51401901245117\n",
      "Iteration no: 1197 and Loss: 63.513065338134766\n",
      "Iteration no: 1198 and Loss: 63.51209259033203\n",
      "Iteration no: 1199 and Loss: 63.511138916015625\n",
      "Iteration no: 1200 and Loss: 63.510189056396484\n",
      "Iteration no: 1201 and Loss: 63.50922393798828\n",
      "Iteration no: 1202 and Loss: 63.508270263671875\n",
      "Iteration no: 1203 and Loss: 63.5073127746582\n",
      "Iteration no: 1204 and Loss: 63.50635528564453\n",
      "Iteration no: 1205 and Loss: 63.505401611328125\n",
      "Iteration no: 1206 and Loss: 63.504459381103516\n",
      "Iteration no: 1207 and Loss: 63.50351333618164\n",
      "Iteration no: 1208 and Loss: 63.502567291259766\n",
      "Iteration no: 1209 and Loss: 63.50161361694336\n",
      "Iteration no: 1210 and Loss: 63.50065994262695\n",
      "Iteration no: 1211 and Loss: 63.499717712402344\n",
      "Iteration no: 1212 and Loss: 63.498779296875\n",
      "Iteration no: 1213 and Loss: 63.49783706665039\n",
      "Iteration no: 1214 and Loss: 63.496891021728516\n",
      "Iteration no: 1215 and Loss: 63.495948791503906\n",
      "Iteration no: 1216 and Loss: 63.49502182006836\n",
      "Iteration no: 1217 and Loss: 63.49409103393555\n",
      "Iteration no: 1218 and Loss: 63.49315643310547\n",
      "Iteration no: 1219 and Loss: 63.49220275878906\n",
      "Iteration no: 1220 and Loss: 63.49125671386719\n",
      "Iteration no: 1221 and Loss: 63.49034118652344\n",
      "Iteration no: 1222 and Loss: 63.48940658569336\n",
      "Iteration no: 1223 and Loss: 63.48849105834961\n",
      "Iteration no: 1224 and Loss: 63.48754119873047\n",
      "Iteration no: 1225 and Loss: 63.48662567138672\n",
      "Iteration no: 1226 and Loss: 63.4857177734375\n",
      "Iteration no: 1227 and Loss: 63.484798431396484\n",
      "Iteration no: 1228 and Loss: 63.48389434814453\n",
      "Iteration no: 1229 and Loss: 63.48298263549805\n",
      "Iteration no: 1230 and Loss: 63.48210906982422\n",
      "Iteration no: 1231 and Loss: 63.481197357177734\n",
      "Iteration no: 1232 and Loss: 63.480281829833984\n",
      "Iteration no: 1233 and Loss: 63.4793815612793\n",
      "Iteration no: 1234 and Loss: 63.47846603393555\n",
      "Iteration no: 1235 and Loss: 63.477569580078125\n",
      "Iteration no: 1236 and Loss: 63.47665786743164\n",
      "Iteration no: 1237 and Loss: 63.475765228271484\n",
      "Iteration no: 1238 and Loss: 63.47486877441406\n",
      "Iteration no: 1239 and Loss: 63.47397232055664\n",
      "Iteration no: 1240 and Loss: 63.47306823730469\n",
      "Iteration no: 1241 and Loss: 63.47218704223633\n",
      "Iteration no: 1242 and Loss: 63.471275329589844\n",
      "Iteration no: 1243 and Loss: 63.470394134521484\n",
      "Iteration no: 1244 and Loss: 63.46950149536133\n",
      "Iteration no: 1245 and Loss: 63.468605041503906\n",
      "Iteration no: 1246 and Loss: 63.46772384643555\n",
      "Iteration no: 1247 and Loss: 63.46683120727539\n",
      "Iteration no: 1248 and Loss: 63.46595764160156\n",
      "Iteration no: 1249 and Loss: 63.4650764465332\n",
      "Iteration no: 1250 and Loss: 63.46419143676758\n",
      "Iteration no: 1251 and Loss: 63.46332550048828\n",
      "Iteration no: 1252 and Loss: 63.46242904663086\n",
      "Iteration no: 1253 and Loss: 63.461551666259766\n",
      "Iteration no: 1254 and Loss: 63.46067428588867\n",
      "Iteration no: 1255 and Loss: 63.45978927612305\n",
      "Iteration no: 1256 and Loss: 63.45891571044922\n",
      "Iteration no: 1257 and Loss: 63.45804214477539\n",
      "Iteration no: 1258 and Loss: 63.457183837890625\n",
      "Iteration no: 1259 and Loss: 63.45631408691406\n",
      "Iteration no: 1260 and Loss: 63.4554443359375\n",
      "Iteration no: 1261 and Loss: 63.45457458496094\n",
      "Iteration no: 1262 and Loss: 63.45370101928711\n",
      "Iteration no: 1263 and Loss: 63.45284652709961\n",
      "Iteration no: 1264 and Loss: 63.45197296142578\n",
      "Iteration no: 1265 and Loss: 63.45112228393555\n",
      "Iteration no: 1266 and Loss: 63.450260162353516\n",
      "Iteration no: 1267 and Loss: 63.44939422607422\n",
      "Iteration no: 1268 and Loss: 63.448543548583984\n",
      "Iteration no: 1269 and Loss: 63.447669982910156\n",
      "Iteration no: 1270 and Loss: 63.44681930541992\n",
      "Iteration no: 1271 and Loss: 63.445960998535156\n",
      "Iteration no: 1272 and Loss: 63.445106506347656\n",
      "Iteration no: 1273 and Loss: 63.44424819946289\n",
      "Iteration no: 1274 and Loss: 63.44338607788086\n",
      "Iteration no: 1275 and Loss: 63.442508697509766\n",
      "Iteration no: 1276 and Loss: 63.441650390625\n",
      "Iteration no: 1277 and Loss: 63.44076919555664\n",
      "Iteration no: 1278 and Loss: 63.43987274169922\n",
      "Iteration no: 1279 and Loss: 63.438968658447266\n",
      "Iteration no: 1280 and Loss: 63.43809509277344\n",
      "Iteration no: 1281 and Loss: 63.43720245361328\n",
      "Iteration no: 1282 and Loss: 63.436336517333984\n",
      "Iteration no: 1283 and Loss: 63.43547439575195\n",
      "Iteration no: 1284 and Loss: 63.434608459472656\n",
      "Iteration no: 1285 and Loss: 63.433753967285156\n",
      "Iteration no: 1286 and Loss: 63.43288803100586\n",
      "Iteration no: 1287 and Loss: 63.43203353881836\n",
      "Iteration no: 1288 and Loss: 63.43117904663086\n",
      "Iteration no: 1289 and Loss: 63.43033981323242\n",
      "Iteration no: 1290 and Loss: 63.42949676513672\n",
      "Iteration no: 1291 and Loss: 63.42863082885742\n",
      "Iteration no: 1292 and Loss: 63.42777633666992\n",
      "Iteration no: 1293 and Loss: 63.42694091796875\n",
      "Iteration no: 1294 and Loss: 63.42609786987305\n",
      "Iteration no: 1295 and Loss: 63.425254821777344\n",
      "Iteration no: 1296 and Loss: 63.424400329589844\n",
      "Iteration no: 1297 and Loss: 63.423561096191406\n",
      "Iteration no: 1298 and Loss: 63.422725677490234\n",
      "Iteration no: 1299 and Loss: 63.42188262939453\n",
      "Iteration no: 1300 and Loss: 63.42103576660156\n",
      "Iteration no: 1301 and Loss: 63.42021179199219\n",
      "Iteration no: 1302 and Loss: 63.419376373291016\n",
      "Iteration no: 1303 and Loss: 63.418521881103516\n",
      "Iteration no: 1304 and Loss: 63.41769027709961\n",
      "Iteration no: 1305 and Loss: 63.41684341430664\n",
      "Iteration no: 1306 and Loss: 63.416015625\n",
      "Iteration no: 1307 and Loss: 63.4151725769043\n",
      "Iteration no: 1308 and Loss: 63.41435241699219\n",
      "Iteration no: 1309 and Loss: 63.413516998291016\n",
      "Iteration no: 1310 and Loss: 63.41270446777344\n",
      "Iteration no: 1311 and Loss: 63.41185760498047\n",
      "Iteration no: 1312 and Loss: 63.41102981567383\n",
      "Iteration no: 1313 and Loss: 63.410194396972656\n",
      "Iteration no: 1314 and Loss: 63.409385681152344\n",
      "Iteration no: 1315 and Loss: 63.40856170654297\n",
      "Iteration no: 1316 and Loss: 63.407737731933594\n",
      "Iteration no: 1317 and Loss: 63.40691375732422\n",
      "Iteration no: 1318 and Loss: 63.40609359741211\n",
      "Iteration no: 1319 and Loss: 63.40528869628906\n",
      "Iteration no: 1320 and Loss: 63.404441833496094\n",
      "Iteration no: 1321 and Loss: 63.40364074707031\n",
      "Iteration no: 1322 and Loss: 63.40282440185547\n",
      "Iteration no: 1323 and Loss: 63.402000427246094\n",
      "Iteration no: 1324 and Loss: 63.40119552612305\n",
      "Iteration no: 1325 and Loss: 63.4003791809082\n",
      "Iteration no: 1326 and Loss: 63.399566650390625\n",
      "Iteration no: 1327 and Loss: 63.39875411987305\n",
      "Iteration no: 1328 and Loss: 63.39794158935547\n",
      "Iteration no: 1329 and Loss: 63.39714050292969\n",
      "Iteration no: 1330 and Loss: 63.396339416503906\n",
      "Iteration no: 1331 and Loss: 63.39553451538086\n",
      "Iteration no: 1332 and Loss: 63.39472198486328\n",
      "Iteration no: 1333 and Loss: 63.3939208984375\n",
      "Iteration no: 1334 and Loss: 63.393157958984375\n",
      "Iteration no: 1335 and Loss: 63.39238739013672\n",
      "Iteration no: 1336 and Loss: 63.3916130065918\n",
      "Iteration no: 1337 and Loss: 63.390838623046875\n",
      "Iteration no: 1338 and Loss: 63.39006805419922\n",
      "Iteration no: 1339 and Loss: 63.38930892944336\n",
      "Iteration no: 1340 and Loss: 63.38852310180664\n",
      "Iteration no: 1341 and Loss: 63.38775634765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration no: 1342 and Loss: 63.3869743347168\n",
      "Iteration no: 1343 and Loss: 63.386207580566406\n",
      "Iteration no: 1344 and Loss: 63.385459899902344\n",
      "Iteration no: 1345 and Loss: 63.384681701660156\n",
      "Iteration no: 1346 and Loss: 63.3839225769043\n",
      "Iteration no: 1347 and Loss: 63.38313293457031\n",
      "Iteration no: 1348 and Loss: 63.38237762451172\n",
      "Iteration no: 1349 and Loss: 63.38161849975586\n",
      "Iteration no: 1350 and Loss: 63.380855560302734\n",
      "Iteration no: 1351 and Loss: 63.380096435546875\n",
      "Iteration no: 1352 and Loss: 63.37933349609375\n",
      "Iteration no: 1353 and Loss: 63.378578186035156\n",
      "Iteration no: 1354 and Loss: 63.3778190612793\n",
      "Iteration no: 1355 and Loss: 63.377052307128906\n",
      "Iteration no: 1356 and Loss: 63.37630081176758\n",
      "Iteration no: 1357 and Loss: 63.37556076049805\n",
      "Iteration no: 1358 and Loss: 63.37479019165039\n",
      "Iteration no: 1359 and Loss: 63.37404251098633\n",
      "Iteration no: 1360 and Loss: 63.3732795715332\n",
      "Iteration no: 1361 and Loss: 63.37254333496094\n",
      "Iteration no: 1362 and Loss: 63.371788024902344\n",
      "Iteration no: 1363 and Loss: 63.37103271484375\n",
      "Iteration no: 1364 and Loss: 63.37029266357422\n",
      "Iteration no: 1365 and Loss: 63.36954116821289\n",
      "Iteration no: 1366 and Loss: 63.36880111694336\n",
      "Iteration no: 1367 and Loss: 63.3680534362793\n",
      "Iteration no: 1368 and Loss: 63.36730194091797\n",
      "Iteration no: 1369 and Loss: 63.36656188964844\n",
      "Iteration no: 1370 and Loss: 63.36581802368164\n",
      "Iteration no: 1371 and Loss: 63.36508560180664\n",
      "Iteration no: 1372 and Loss: 63.36436462402344\n",
      "Iteration no: 1373 and Loss: 63.36362075805664\n",
      "Iteration no: 1374 and Loss: 63.36289978027344\n",
      "Iteration no: 1375 and Loss: 63.36215591430664\n",
      "Iteration no: 1376 and Loss: 63.361412048339844\n",
      "Iteration no: 1377 and Loss: 63.36068344116211\n",
      "Iteration no: 1378 and Loss: 63.35995864868164\n",
      "Iteration no: 1379 and Loss: 63.359230041503906\n",
      "Iteration no: 1380 and Loss: 63.358489990234375\n",
      "Iteration no: 1381 and Loss: 63.35777282714844\n",
      "Iteration no: 1382 and Loss: 63.35704040527344\n",
      "Iteration no: 1383 and Loss: 63.35631561279297\n",
      "Iteration no: 1384 and Loss: 63.355594635009766\n",
      "Iteration no: 1385 and Loss: 63.35487747192383\n",
      "Iteration no: 1386 and Loss: 63.3541374206543\n",
      "Iteration no: 1387 and Loss: 63.35342025756836\n",
      "Iteration no: 1388 and Loss: 63.35270690917969\n",
      "Iteration no: 1389 and Loss: 63.351993560791016\n",
      "Iteration no: 1390 and Loss: 63.35126495361328\n",
      "Iteration no: 1391 and Loss: 63.35056686401367\n",
      "Iteration no: 1392 and Loss: 63.34983444213867\n",
      "Iteration no: 1393 and Loss: 63.3491325378418\n",
      "Iteration no: 1394 and Loss: 63.34839630126953\n",
      "Iteration no: 1395 and Loss: 63.347694396972656\n",
      "Iteration no: 1396 and Loss: 63.34700012207031\n",
      "Iteration no: 1397 and Loss: 63.34627914428711\n",
      "Iteration no: 1398 and Loss: 63.34554672241211\n",
      "Iteration no: 1399 and Loss: 63.344852447509766\n",
      "Iteration no: 1400 and Loss: 63.34416580200195\n",
      "Iteration no: 1401 and Loss: 63.343441009521484\n",
      "Iteration no: 1402 and Loss: 63.342735290527344\n",
      "Iteration no: 1403 and Loss: 63.34204864501953\n",
      "Iteration no: 1404 and Loss: 63.34135818481445\n",
      "Iteration no: 1405 and Loss: 63.340660095214844\n",
      "Iteration no: 1406 and Loss: 63.3399772644043\n",
      "Iteration no: 1407 and Loss: 63.339298248291016\n",
      "Iteration no: 1408 and Loss: 63.338600158691406\n",
      "Iteration no: 1409 and Loss: 63.33790969848633\n",
      "Iteration no: 1410 and Loss: 63.33721923828125\n",
      "Iteration no: 1411 and Loss: 63.3365478515625\n",
      "Iteration no: 1412 and Loss: 63.33584213256836\n",
      "Iteration no: 1413 and Loss: 63.33516311645508\n",
      "Iteration no: 1414 and Loss: 63.334468841552734\n",
      "Iteration no: 1415 and Loss: 63.33379364013672\n",
      "Iteration no: 1416 and Loss: 63.33311080932617\n",
      "Iteration no: 1417 and Loss: 63.332427978515625\n",
      "Iteration no: 1418 and Loss: 63.33174514770508\n",
      "Iteration no: 1419 and Loss: 63.331050872802734\n",
      "Iteration no: 1420 and Loss: 63.33036422729492\n",
      "Iteration no: 1421 and Loss: 63.32972717285156\n",
      "Iteration no: 1422 and Loss: 63.32901382446289\n",
      "Iteration no: 1423 and Loss: 63.32834243774414\n",
      "Iteration no: 1424 and Loss: 63.32766342163086\n",
      "Iteration no: 1425 and Loss: 63.32698440551758\n",
      "Iteration no: 1426 and Loss: 63.32630920410156\n",
      "Iteration no: 1427 and Loss: 63.32563400268555\n",
      "Iteration no: 1428 and Loss: 63.32497024536133\n",
      "Iteration no: 1429 and Loss: 63.32432174682617\n",
      "Iteration no: 1430 and Loss: 63.323665618896484\n",
      "Iteration no: 1431 and Loss: 63.323036193847656\n",
      "Iteration no: 1432 and Loss: 63.322383880615234\n",
      "Iteration no: 1433 and Loss: 63.32173156738281\n",
      "Iteration no: 1434 and Loss: 63.32109451293945\n",
      "Iteration no: 1435 and Loss: 63.320438385009766\n",
      "Iteration no: 1436 and Loss: 63.31977844238281\n",
      "Iteration no: 1437 and Loss: 63.319122314453125\n",
      "Iteration no: 1438 and Loss: 63.318477630615234\n",
      "Iteration no: 1439 and Loss: 63.31782913208008\n",
      "Iteration no: 1440 and Loss: 63.31718826293945\n",
      "Iteration no: 1441 and Loss: 63.31653594970703\n",
      "Iteration no: 1442 and Loss: 63.31589126586914\n",
      "Iteration no: 1443 and Loss: 63.315250396728516\n",
      "Iteration no: 1444 and Loss: 63.314605712890625\n",
      "Iteration no: 1445 and Loss: 63.31394577026367\n",
      "Iteration no: 1446 and Loss: 63.31330108642578\n",
      "Iteration no: 1447 and Loss: 63.312652587890625\n",
      "Iteration no: 1448 and Loss: 63.312007904052734\n",
      "Iteration no: 1449 and Loss: 63.31135940551758\n",
      "Iteration no: 1450 and Loss: 63.31071853637695\n",
      "Iteration no: 1451 and Loss: 63.31005096435547\n",
      "Iteration no: 1452 and Loss: 63.30939865112305\n",
      "Iteration no: 1453 and Loss: 63.308746337890625\n",
      "Iteration no: 1454 and Loss: 63.30807113647461\n",
      "Iteration no: 1455 and Loss: 63.30742263793945\n",
      "Iteration no: 1456 and Loss: 63.3067741394043\n",
      "Iteration no: 1457 and Loss: 63.306129455566406\n",
      "Iteration no: 1458 and Loss: 63.30549240112305\n",
      "Iteration no: 1459 and Loss: 63.304813385009766\n",
      "Iteration no: 1460 and Loss: 63.30416488647461\n",
      "Iteration no: 1461 and Loss: 63.303524017333984\n",
      "Iteration no: 1462 and Loss: 63.30288314819336\n",
      "Iteration no: 1463 and Loss: 63.30223083496094\n",
      "Iteration no: 1464 and Loss: 63.30158233642578\n",
      "Iteration no: 1465 and Loss: 63.300941467285156\n",
      "Iteration no: 1466 and Loss: 63.30028533935547\n",
      "Iteration no: 1467 and Loss: 63.29963302612305\n",
      "Iteration no: 1468 and Loss: 63.29900360107422\n",
      "Iteration no: 1469 and Loss: 63.29834747314453\n",
      "Iteration no: 1470 and Loss: 63.29770278930664\n",
      "Iteration no: 1471 and Loss: 63.29705810546875\n",
      "Iteration no: 1472 and Loss: 63.29640197753906\n",
      "Iteration no: 1473 and Loss: 63.29576873779297\n",
      "Iteration no: 1474 and Loss: 63.29513931274414\n",
      "Iteration no: 1475 and Loss: 63.29448699951172\n",
      "Iteration no: 1476 and Loss: 63.29385757446289\n",
      "Iteration no: 1477 and Loss: 63.29320526123047\n",
      "Iteration no: 1478 and Loss: 63.29258728027344\n",
      "Iteration no: 1479 and Loss: 63.291954040527344\n",
      "Iteration no: 1480 and Loss: 63.29130554199219\n",
      "Iteration no: 1481 and Loss: 63.2906494140625\n",
      "Iteration no: 1482 and Loss: 63.28997802734375\n",
      "Iteration no: 1483 and Loss: 63.28931427001953\n",
      "Iteration no: 1484 and Loss: 63.288631439208984\n",
      "Iteration no: 1485 and Loss: 63.28795623779297\n",
      "Iteration no: 1486 and Loss: 63.28727722167969\n",
      "Iteration no: 1487 and Loss: 63.286582946777344\n",
      "Iteration no: 1488 and Loss: 63.285911560058594\n",
      "Iteration no: 1489 and Loss: 63.28523635864258\n",
      "Iteration no: 1490 and Loss: 63.2845458984375\n",
      "Iteration no: 1491 and Loss: 63.28386306762695\n",
      "Iteration no: 1492 and Loss: 63.28317642211914\n",
      "Iteration no: 1493 and Loss: 63.28248977661133\n",
      "Iteration no: 1494 and Loss: 63.28180694580078\n",
      "Iteration no: 1495 and Loss: 63.281124114990234\n",
      "Iteration no: 1496 and Loss: 63.280433654785156\n",
      "Iteration no: 1497 and Loss: 63.279762268066406\n",
      "Iteration no: 1498 and Loss: 63.27906799316406\n",
      "Iteration no: 1499 and Loss: 63.27839279174805\n",
      "Iteration no: 1500 and Loss: 63.2777099609375\n",
      "Iteration no: 1501 and Loss: 63.27702331542969\n",
      "Iteration no: 1502 and Loss: 63.27635955810547\n",
      "Iteration no: 1503 and Loss: 63.275657653808594\n",
      "Iteration no: 1504 and Loss: 63.275001525878906\n",
      "Iteration no: 1505 and Loss: 63.274322509765625\n",
      "Iteration no: 1506 and Loss: 63.27363204956055\n",
      "Iteration no: 1507 and Loss: 63.272953033447266\n",
      "Iteration no: 1508 and Loss: 63.272281646728516\n",
      "Iteration no: 1509 and Loss: 63.2716064453125\n",
      "Iteration no: 1510 and Loss: 63.27092742919922\n",
      "Iteration no: 1511 and Loss: 63.270259857177734\n",
      "Iteration no: 1512 and Loss: 63.269569396972656\n",
      "Iteration no: 1513 and Loss: 63.26890563964844\n",
      "Iteration no: 1514 and Loss: 63.26823425292969\n",
      "Iteration no: 1515 and Loss: 63.2675666809082\n",
      "Iteration no: 1516 and Loss: 63.266902923583984\n",
      "Iteration no: 1517 and Loss: 63.26624298095703\n",
      "Iteration no: 1518 and Loss: 63.265567779541016\n",
      "Iteration no: 1519 and Loss: 63.2649040222168\n",
      "Iteration no: 1520 and Loss: 63.26424789428711\n",
      "Iteration no: 1521 and Loss: 63.26359558105469\n",
      "Iteration no: 1522 and Loss: 63.26297378540039\n",
      "Iteration no: 1523 and Loss: 63.26236343383789\n",
      "Iteration no: 1524 and Loss: 63.26176452636719\n",
      "Iteration no: 1525 and Loss: 63.26116943359375\n",
      "Iteration no: 1526 and Loss: 63.26055908203125\n",
      "Iteration no: 1527 and Loss: 63.25996017456055\n",
      "Iteration no: 1528 and Loss: 63.25937271118164\n",
      "Iteration no: 1529 and Loss: 63.258819580078125\n",
      "Iteration no: 1530 and Loss: 63.258304595947266\n",
      "Iteration no: 1531 and Loss: 63.25778579711914\n",
      "Iteration no: 1532 and Loss: 63.25727462768555\n",
      "Iteration no: 1533 and Loss: 63.256771087646484\n",
      "Iteration no: 1534 and Loss: 63.25627136230469\n",
      "Iteration no: 1535 and Loss: 63.25576400756836\n",
      "Iteration no: 1536 and Loss: 63.25528335571289\n",
      "Iteration no: 1537 and Loss: 63.25478744506836\n",
      "Iteration no: 1538 and Loss: 63.25430679321289\n",
      "Iteration no: 1539 and Loss: 63.25380325317383\n",
      "Iteration no: 1540 and Loss: 63.25331115722656\n",
      "Iteration no: 1541 and Loss: 63.25279998779297\n",
      "Iteration no: 1542 and Loss: 63.25230026245117\n",
      "Iteration no: 1543 and Loss: 63.251800537109375\n",
      "Iteration no: 1544 and Loss: 63.251319885253906\n",
      "Iteration no: 1545 and Loss: 63.25081253051758\n",
      "Iteration no: 1546 and Loss: 63.25031661987305\n",
      "Iteration no: 1547 and Loss: 63.24983215332031\n",
      "Iteration no: 1548 and Loss: 63.24934768676758\n",
      "Iteration no: 1549 and Loss: 63.24885559082031\n",
      "Iteration no: 1550 and Loss: 63.248374938964844\n",
      "Iteration no: 1551 and Loss: 63.24787902832031\n",
      "Iteration no: 1552 and Loss: 63.247406005859375\n",
      "Iteration no: 1553 and Loss: 63.246910095214844\n",
      "Iteration no: 1554 and Loss: 63.24641036987305\n",
      "Iteration no: 1555 and Loss: 63.24593734741211\n",
      "Iteration no: 1556 and Loss: 63.245445251464844\n",
      "Iteration no: 1557 and Loss: 63.24496078491211\n",
      "Iteration no: 1558 and Loss: 63.24449157714844\n",
      "Iteration no: 1559 and Loss: 63.24399948120117\n",
      "Iteration no: 1560 and Loss: 63.24351119995117\n",
      "Iteration no: 1561 and Loss: 63.24305725097656\n",
      "Iteration no: 1562 and Loss: 63.24257278442383\n",
      "Iteration no: 1563 and Loss: 63.24208068847656\n",
      "Iteration no: 1564 and Loss: 63.241607666015625\n",
      "Iteration no: 1565 and Loss: 63.241127014160156\n",
      "Iteration no: 1566 and Loss: 63.24065017700195\n",
      "Iteration no: 1567 and Loss: 63.240169525146484\n",
      "Iteration no: 1568 and Loss: 63.23970031738281\n",
      "Iteration no: 1569 and Loss: 63.23922348022461\n",
      "Iteration no: 1570 and Loss: 63.23876190185547\n",
      "Iteration no: 1571 and Loss: 63.2382698059082\n",
      "Iteration no: 1572 and Loss: 63.2378044128418\n",
      "Iteration no: 1573 and Loss: 63.237327575683594\n",
      "Iteration no: 1574 and Loss: 63.23686218261719\n",
      "Iteration no: 1575 and Loss: 63.23637771606445\n",
      "Iteration no: 1576 and Loss: 63.235897064208984\n",
      "Iteration no: 1577 and Loss: 63.23542404174805\n",
      "Iteration no: 1578 and Loss: 63.2349853515625\n",
      "Iteration no: 1579 and Loss: 63.234500885009766\n",
      "Iteration no: 1580 and Loss: 63.23402404785156\n",
      "Iteration no: 1581 and Loss: 63.23356246948242\n",
      "Iteration no: 1582 and Loss: 63.233097076416016\n",
      "Iteration no: 1583 and Loss: 63.23263168334961\n",
      "Iteration no: 1584 and Loss: 63.232147216796875\n",
      "Iteration no: 1585 and Loss: 63.231685638427734\n",
      "Iteration no: 1586 and Loss: 63.23122787475586\n",
      "Iteration no: 1587 and Loss: 63.23076629638672\n",
      "Iteration no: 1588 and Loss: 63.23030471801758\n",
      "Iteration no: 1589 and Loss: 63.22983932495117\n",
      "Iteration no: 1590 and Loss: 63.2293701171875\n",
      "Iteration no: 1591 and Loss: 63.22889709472656\n",
      "Iteration no: 1592 and Loss: 63.228458404541016\n",
      "Iteration no: 1593 and Loss: 63.22798538208008\n",
      "Iteration no: 1594 and Loss: 63.22753143310547\n",
      "Iteration no: 1595 and Loss: 63.22707748413086\n",
      "Iteration no: 1596 and Loss: 63.22659683227539\n",
      "Iteration no: 1597 and Loss: 63.226139068603516\n",
      "Iteration no: 1598 and Loss: 63.22569274902344\n",
      "Iteration no: 1599 and Loss: 63.225242614746094\n",
      "Iteration no: 1600 and Loss: 63.22478485107422\n",
      "Iteration no: 1601 and Loss: 63.22431564331055\n",
      "Iteration no: 1602 and Loss: 63.22385787963867\n",
      "Iteration no: 1603 and Loss: 63.223384857177734\n",
      "Iteration no: 1604 and Loss: 63.22293472290039\n",
      "Iteration no: 1605 and Loss: 63.22248840332031\n",
      "Iteration no: 1606 and Loss: 63.222015380859375\n",
      "Iteration no: 1607 and Loss: 63.221561431884766\n",
      "Iteration no: 1608 and Loss: 63.221099853515625\n",
      "Iteration no: 1609 and Loss: 63.22065353393555\n",
      "Iteration no: 1610 and Loss: 63.2202033996582\n",
      "Iteration no: 1611 and Loss: 63.21974563598633\n",
      "Iteration no: 1612 and Loss: 63.21928787231445\n",
      "Iteration no: 1613 and Loss: 63.218841552734375\n",
      "Iteration no: 1614 and Loss: 63.218379974365234\n",
      "Iteration no: 1615 and Loss: 63.217933654785156\n",
      "Iteration no: 1616 and Loss: 63.21748733520508\n",
      "Iteration no: 1617 and Loss: 63.21702194213867\n",
      "Iteration no: 1618 and Loss: 63.216590881347656\n",
      "Iteration no: 1619 and Loss: 63.21613693237305\n",
      "Iteration no: 1620 and Loss: 63.2156867980957\n",
      "Iteration no: 1621 and Loss: 63.21525192260742\n",
      "Iteration no: 1622 and Loss: 63.214805603027344\n",
      "Iteration no: 1623 and Loss: 63.21435546875\n",
      "Iteration no: 1624 and Loss: 63.21391296386719\n",
      "Iteration no: 1625 and Loss: 63.213470458984375\n",
      "Iteration no: 1626 and Loss: 63.213008880615234\n",
      "Iteration no: 1627 and Loss: 63.21255111694336\n",
      "Iteration no: 1628 and Loss: 63.2120361328125\n",
      "Iteration no: 1629 and Loss: 63.21156692504883\n",
      "Iteration no: 1630 and Loss: 63.21108627319336\n",
      "Iteration no: 1631 and Loss: 63.21058654785156\n",
      "Iteration no: 1632 and Loss: 63.21006393432617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration no: 1633 and Loss: 63.20956802368164\n",
      "Iteration no: 1634 and Loss: 63.20905303955078\n",
      "Iteration no: 1635 and Loss: 63.208560943603516\n",
      "Iteration no: 1636 and Loss: 63.20805740356445\n",
      "Iteration no: 1637 and Loss: 63.207557678222656\n",
      "Iteration no: 1638 and Loss: 63.20703125\n",
      "Iteration no: 1639 and Loss: 63.206539154052734\n",
      "Iteration no: 1640 and Loss: 63.20600891113281\n",
      "Iteration no: 1641 and Loss: 63.20549774169922\n",
      "Iteration no: 1642 and Loss: 63.20500183105469\n",
      "Iteration no: 1643 and Loss: 63.20450973510742\n",
      "Iteration no: 1644 and Loss: 63.20396423339844\n",
      "Iteration no: 1645 and Loss: 63.20344924926758\n",
      "Iteration no: 1646 and Loss: 63.202938079833984\n",
      "Iteration no: 1647 and Loss: 63.202430725097656\n",
      "Iteration no: 1648 and Loss: 63.201927185058594\n",
      "Iteration no: 1649 and Loss: 63.201416015625\n",
      "Iteration no: 1650 and Loss: 63.20089340209961\n",
      "Iteration no: 1651 and Loss: 63.20038604736328\n",
      "Iteration no: 1652 and Loss: 63.19987106323242\n",
      "Iteration no: 1653 and Loss: 63.19935607910156\n",
      "Iteration no: 1654 and Loss: 63.1988410949707\n",
      "Iteration no: 1655 and Loss: 63.198341369628906\n",
      "Iteration no: 1656 and Loss: 63.197845458984375\n",
      "Iteration no: 1657 and Loss: 63.197330474853516\n",
      "Iteration no: 1658 and Loss: 63.19679260253906\n",
      "Iteration no: 1659 and Loss: 63.19629669189453\n",
      "Iteration no: 1660 and Loss: 63.19578170776367\n",
      "Iteration no: 1661 and Loss: 63.19529724121094\n",
      "Iteration no: 1662 and Loss: 63.19478225708008\n",
      "Iteration no: 1663 and Loss: 63.19426345825195\n",
      "Iteration no: 1664 and Loss: 63.193763732910156\n",
      "Iteration no: 1665 and Loss: 63.193241119384766\n",
      "Iteration no: 1666 and Loss: 63.1927375793457\n",
      "Iteration no: 1667 and Loss: 63.192222595214844\n",
      "Iteration no: 1668 and Loss: 63.191707611083984\n",
      "Iteration no: 1669 and Loss: 63.19121170043945\n",
      "Iteration no: 1670 and Loss: 63.19069290161133\n",
      "Iteration no: 1671 and Loss: 63.190189361572266\n",
      "Iteration no: 1672 and Loss: 63.18968963623047\n",
      "Iteration no: 1673 and Loss: 63.189186096191406\n",
      "Iteration no: 1674 and Loss: 63.188682556152344\n",
      "Iteration no: 1675 and Loss: 63.18817138671875\n",
      "Iteration no: 1676 and Loss: 63.18767547607422\n",
      "Iteration no: 1677 and Loss: 63.18716049194336\n",
      "Iteration no: 1678 and Loss: 63.186676025390625\n",
      "Iteration no: 1679 and Loss: 63.186180114746094\n",
      "Iteration no: 1680 and Loss: 63.185672760009766\n",
      "Iteration no: 1681 and Loss: 63.1851692199707\n",
      "Iteration no: 1682 and Loss: 63.184669494628906\n",
      "Iteration no: 1683 and Loss: 63.184181213378906\n",
      "Iteration no: 1684 and Loss: 63.18367385864258\n",
      "Iteration no: 1685 and Loss: 63.183170318603516\n",
      "Iteration no: 1686 and Loss: 63.182682037353516\n",
      "Iteration no: 1687 and Loss: 63.182186126708984\n",
      "Iteration no: 1688 and Loss: 63.181697845458984\n",
      "Iteration no: 1689 and Loss: 63.181182861328125\n",
      "Iteration no: 1690 and Loss: 63.18069839477539\n",
      "Iteration no: 1691 and Loss: 63.18021011352539\n",
      "Iteration no: 1692 and Loss: 63.17971420288086\n",
      "Iteration no: 1693 and Loss: 63.1792106628418\n",
      "Iteration no: 1694 and Loss: 63.1787223815918\n",
      "Iteration no: 1695 and Loss: 63.17821502685547\n",
      "Iteration no: 1696 and Loss: 63.177730560302734\n",
      "Iteration no: 1697 and Loss: 63.177249908447266\n",
      "Iteration no: 1698 and Loss: 63.1767463684082\n",
      "Iteration no: 1699 and Loss: 63.1762580871582\n",
      "Iteration no: 1700 and Loss: 63.17576599121094\n",
      "Iteration no: 1701 and Loss: 63.1752815246582\n",
      "Iteration no: 1702 and Loss: 63.17478561401367\n",
      "Iteration no: 1703 and Loss: 63.17430114746094\n",
      "Iteration no: 1704 and Loss: 63.17380905151367\n",
      "Iteration no: 1705 and Loss: 63.17332458496094\n",
      "Iteration no: 1706 and Loss: 63.172821044921875\n",
      "Iteration no: 1707 and Loss: 63.17236328125\n",
      "Iteration no: 1708 and Loss: 63.17186737060547\n",
      "Iteration no: 1709 and Loss: 63.1713752746582\n",
      "Iteration no: 1710 and Loss: 63.170875549316406\n",
      "Iteration no: 1711 and Loss: 63.17041015625\n",
      "Iteration no: 1712 and Loss: 63.169921875\n",
      "Iteration no: 1713 and Loss: 63.169437408447266\n",
      "Iteration no: 1714 and Loss: 63.16896057128906\n",
      "Iteration no: 1715 and Loss: 63.16845703125\n",
      "Iteration no: 1716 and Loss: 63.16798782348633\n",
      "Iteration no: 1717 and Loss: 63.16749572753906\n",
      "Iteration no: 1718 and Loss: 63.167022705078125\n",
      "Iteration no: 1719 and Loss: 63.16653823852539\n",
      "Iteration no: 1720 and Loss: 63.16604232788086\n",
      "Iteration no: 1721 and Loss: 63.16557312011719\n",
      "Iteration no: 1722 and Loss: 63.16509246826172\n",
      "Iteration no: 1723 and Loss: 63.16462326049805\n",
      "Iteration no: 1724 and Loss: 63.16415023803711\n",
      "Iteration no: 1725 and Loss: 63.163658142089844\n",
      "Iteration no: 1726 and Loss: 63.16318130493164\n",
      "Iteration no: 1727 and Loss: 63.16270446777344\n",
      "Iteration no: 1728 and Loss: 63.162227630615234\n",
      "Iteration no: 1729 and Loss: 63.161766052246094\n",
      "Iteration no: 1730 and Loss: 63.16128158569336\n",
      "Iteration no: 1731 and Loss: 63.160797119140625\n",
      "Iteration no: 1732 and Loss: 63.16033172607422\n",
      "Iteration no: 1733 and Loss: 63.159854888916016\n",
      "Iteration no: 1734 and Loss: 63.15937423706055\n",
      "Iteration no: 1735 and Loss: 63.15890884399414\n",
      "Iteration no: 1736 and Loss: 63.15843200683594\n",
      "Iteration no: 1737 and Loss: 63.157958984375\n",
      "Iteration no: 1738 and Loss: 63.1574821472168\n",
      "Iteration no: 1739 and Loss: 63.15702438354492\n",
      "Iteration no: 1740 and Loss: 63.15653610229492\n",
      "Iteration no: 1741 and Loss: 63.15606689453125\n",
      "Iteration no: 1742 and Loss: 63.15559768676758\n",
      "Iteration no: 1743 and Loss: 63.15513610839844\n",
      "Iteration no: 1744 and Loss: 63.15467834472656\n",
      "Iteration no: 1745 and Loss: 63.154197692871094\n",
      "Iteration no: 1746 and Loss: 63.15372848510742\n",
      "Iteration no: 1747 and Loss: 63.15325927734375\n",
      "Iteration no: 1748 and Loss: 63.15279769897461\n",
      "Iteration no: 1749 and Loss: 63.15232467651367\n",
      "Iteration no: 1750 and Loss: 63.151851654052734\n",
      "Iteration no: 1751 and Loss: 63.15139389038086\n",
      "Iteration no: 1752 and Loss: 63.15092468261719\n",
      "Iteration no: 1753 and Loss: 63.150455474853516\n",
      "Iteration no: 1754 and Loss: 63.149993896484375\n",
      "Iteration no: 1755 and Loss: 63.14952850341797\n",
      "Iteration no: 1756 and Loss: 63.149070739746094\n",
      "Iteration no: 1757 and Loss: 63.14860534667969\n",
      "Iteration no: 1758 and Loss: 63.148136138916016\n",
      "Iteration no: 1759 and Loss: 63.14767837524414\n",
      "Iteration no: 1760 and Loss: 63.14719772338867\n",
      "Iteration no: 1761 and Loss: 63.146751403808594\n",
      "Iteration no: 1762 and Loss: 63.146297454833984\n",
      "Iteration no: 1763 and Loss: 63.14583969116211\n",
      "Iteration no: 1764 and Loss: 63.14537048339844\n",
      "Iteration no: 1765 and Loss: 63.144893646240234\n",
      "Iteration no: 1766 and Loss: 63.14446258544922\n",
      "Iteration no: 1767 and Loss: 63.14398956298828\n",
      "Iteration no: 1768 and Loss: 63.14354705810547\n",
      "Iteration no: 1769 and Loss: 63.14307403564453\n",
      "Iteration no: 1770 and Loss: 63.14262771606445\n",
      "Iteration no: 1771 and Loss: 63.14216232299805\n",
      "Iteration no: 1772 and Loss: 63.141700744628906\n",
      "Iteration no: 1773 and Loss: 63.14124298095703\n",
      "Iteration no: 1774 and Loss: 63.140785217285156\n",
      "Iteration no: 1775 and Loss: 63.14032745361328\n",
      "Iteration no: 1776 and Loss: 63.139888763427734\n",
      "Iteration no: 1777 and Loss: 63.13942337036133\n",
      "Iteration no: 1778 and Loss: 63.13896560668945\n",
      "Iteration no: 1779 and Loss: 63.13851547241211\n",
      "Iteration no: 1780 and Loss: 63.1380615234375\n",
      "Iteration no: 1781 and Loss: 63.13760757446289\n",
      "Iteration no: 1782 and Loss: 63.13715362548828\n",
      "Iteration no: 1783 and Loss: 63.136695861816406\n",
      "Iteration no: 1784 and Loss: 63.13624572753906\n",
      "Iteration no: 1785 and Loss: 63.135799407958984\n",
      "Iteration no: 1786 and Loss: 63.135337829589844\n",
      "Iteration no: 1787 and Loss: 63.134883880615234\n",
      "Iteration no: 1788 and Loss: 63.13444137573242\n",
      "Iteration no: 1789 and Loss: 63.13399124145508\n",
      "Iteration no: 1790 and Loss: 63.13355255126953\n",
      "Iteration no: 1791 and Loss: 63.13311004638672\n",
      "Iteration no: 1792 and Loss: 63.132652282714844\n",
      "Iteration no: 1793 and Loss: 63.13219451904297\n",
      "Iteration no: 1794 and Loss: 63.131752014160156\n",
      "Iteration no: 1795 and Loss: 63.13129806518555\n",
      "Iteration no: 1796 and Loss: 63.13084411621094\n",
      "Iteration no: 1797 and Loss: 63.13041305541992\n",
      "Iteration no: 1798 and Loss: 63.129966735839844\n",
      "Iteration no: 1799 and Loss: 63.129520416259766\n",
      "Iteration no: 1800 and Loss: 63.12907791137695\n",
      "Iteration no: 1801 and Loss: 63.12862014770508\n",
      "Iteration no: 1802 and Loss: 63.12818908691406\n",
      "Iteration no: 1803 and Loss: 63.12773513793945\n",
      "Iteration no: 1804 and Loss: 63.12729263305664\n",
      "Iteration no: 1805 and Loss: 63.12685775756836\n",
      "Iteration no: 1806 and Loss: 63.126407623291016\n",
      "Iteration no: 1807 and Loss: 63.125953674316406\n",
      "Iteration no: 1808 and Loss: 63.12552261352539\n",
      "Iteration no: 1809 and Loss: 63.12508010864258\n",
      "Iteration no: 1810 and Loss: 63.12464141845703\n",
      "Iteration no: 1811 and Loss: 63.12419891357422\n",
      "Iteration no: 1812 and Loss: 63.12376022338867\n",
      "Iteration no: 1813 and Loss: 63.12331771850586\n",
      "Iteration no: 1814 and Loss: 63.12288284301758\n",
      "Iteration no: 1815 and Loss: 63.12244415283203\n",
      "Iteration no: 1816 and Loss: 63.122005462646484\n",
      "Iteration no: 1817 and Loss: 63.12156677246094\n",
      "Iteration no: 1818 and Loss: 63.12112808227539\n",
      "Iteration no: 1819 and Loss: 63.12068557739258\n",
      "Iteration no: 1820 and Loss: 63.1202507019043\n",
      "Iteration no: 1821 and Loss: 63.11981201171875\n",
      "Iteration no: 1822 and Loss: 63.1193733215332\n",
      "Iteration no: 1823 and Loss: 63.11894226074219\n",
      "Iteration no: 1824 and Loss: 63.11850357055664\n",
      "Iteration no: 1825 and Loss: 63.11807632446289\n",
      "Iteration no: 1826 and Loss: 63.11762619018555\n",
      "Iteration no: 1827 and Loss: 63.11719512939453\n",
      "Iteration no: 1828 and Loss: 63.11674880981445\n",
      "Iteration no: 1829 and Loss: 63.1163330078125\n",
      "Iteration no: 1830 and Loss: 63.11589050292969\n",
      "Iteration no: 1831 and Loss: 63.11546325683594\n",
      "Iteration no: 1832 and Loss: 63.115028381347656\n",
      "Iteration no: 1833 and Loss: 63.114593505859375\n",
      "Iteration no: 1834 and Loss: 63.114158630371094\n",
      "Iteration no: 1835 and Loss: 63.113739013671875\n",
      "Iteration no: 1836 and Loss: 63.113304138183594\n",
      "Iteration no: 1837 and Loss: 63.112876892089844\n",
      "Iteration no: 1838 and Loss: 63.11244583129883\n",
      "Iteration no: 1839 and Loss: 63.11199951171875\n",
      "Iteration no: 1840 and Loss: 63.11156463623047\n",
      "Iteration no: 1841 and Loss: 63.111141204833984\n",
      "Iteration no: 1842 and Loss: 63.110713958740234\n",
      "Iteration no: 1843 and Loss: 63.110286712646484\n",
      "Iteration no: 1844 and Loss: 63.109859466552734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration no: 1845 and Loss: 63.109432220458984\n",
      "Iteration no: 1846 and Loss: 63.1090087890625\n",
      "Iteration no: 1847 and Loss: 63.10857009887695\n",
      "Iteration no: 1848 and Loss: 63.108154296875\n",
      "Iteration no: 1849 and Loss: 63.10773468017578\n",
      "Iteration no: 1850 and Loss: 63.10729217529297\n",
      "Iteration no: 1851 and Loss: 63.106868743896484\n",
      "Iteration no: 1852 and Loss: 63.106449127197266\n",
      "Iteration no: 1853 and Loss: 63.10601806640625\n",
      "Iteration no: 1854 and Loss: 63.105594635009766\n",
      "Iteration no: 1855 and Loss: 63.10516357421875\n",
      "Iteration no: 1856 and Loss: 63.104736328125\n",
      "Iteration no: 1857 and Loss: 63.10431671142578\n",
      "Iteration no: 1858 and Loss: 63.1038932800293\n",
      "Iteration no: 1859 and Loss: 63.103485107421875\n",
      "Iteration no: 1860 and Loss: 63.10304260253906\n",
      "Iteration no: 1861 and Loss: 63.10262680053711\n",
      "Iteration no: 1862 and Loss: 63.102203369140625\n",
      "Iteration no: 1863 and Loss: 63.10178756713867\n",
      "Iteration no: 1864 and Loss: 63.10136032104492\n",
      "Iteration no: 1865 and Loss: 63.10094451904297\n",
      "Iteration no: 1866 and Loss: 63.100521087646484\n",
      "Iteration no: 1867 and Loss: 63.100093841552734\n",
      "Iteration no: 1868 and Loss: 63.09968948364258\n",
      "Iteration no: 1869 and Loss: 63.099266052246094\n",
      "Iteration no: 1870 and Loss: 63.09883117675781\n",
      "Iteration no: 1871 and Loss: 63.09841537475586\n",
      "Iteration no: 1872 and Loss: 63.0980110168457\n",
      "Iteration no: 1873 and Loss: 63.09758758544922\n",
      "Iteration no: 1874 and Loss: 63.09716796875\n",
      "Iteration no: 1875 and Loss: 63.09675598144531\n",
      "Iteration no: 1876 and Loss: 63.09632873535156\n",
      "Iteration no: 1877 and Loss: 63.09590530395508\n",
      "Iteration no: 1878 and Loss: 63.095497131347656\n",
      "Iteration no: 1879 and Loss: 63.095088958740234\n",
      "Iteration no: 1880 and Loss: 63.09466552734375\n",
      "Iteration no: 1881 and Loss: 63.094242095947266\n",
      "Iteration no: 1882 and Loss: 63.093841552734375\n",
      "Iteration no: 1883 and Loss: 63.09342575073242\n",
      "Iteration no: 1884 and Loss: 63.093013763427734\n",
      "Iteration no: 1885 and Loss: 63.092594146728516\n",
      "Iteration no: 1886 and Loss: 63.09218215942383\n",
      "Iteration no: 1887 and Loss: 63.09175491333008\n",
      "Iteration no: 1888 and Loss: 63.09135055541992\n",
      "Iteration no: 1889 and Loss: 63.09095001220703\n",
      "Iteration no: 1890 and Loss: 63.090518951416016\n",
      "Iteration no: 1891 and Loss: 63.090118408203125\n",
      "Iteration no: 1892 and Loss: 63.089691162109375\n",
      "Iteration no: 1893 and Loss: 63.08930587768555\n",
      "Iteration no: 1894 and Loss: 63.0888786315918\n",
      "Iteration no: 1895 and Loss: 63.088470458984375\n",
      "Iteration no: 1896 and Loss: 63.08806228637695\n",
      "Iteration no: 1897 and Loss: 63.087650299072266\n",
      "Iteration no: 1898 and Loss: 63.087242126464844\n",
      "Iteration no: 1899 and Loss: 63.08681869506836\n",
      "Iteration no: 1900 and Loss: 63.08644104003906\n",
      "Iteration no: 1901 and Loss: 63.08602523803711\n",
      "Iteration no: 1902 and Loss: 63.08562469482422\n",
      "Iteration no: 1903 and Loss: 63.08519744873047\n",
      "Iteration no: 1904 and Loss: 63.084808349609375\n",
      "Iteration no: 1905 and Loss: 63.08440399169922\n",
      "Iteration no: 1906 and Loss: 63.08399963378906\n",
      "Iteration no: 1907 and Loss: 63.083595275878906\n",
      "Iteration no: 1908 and Loss: 63.083187103271484\n",
      "Iteration no: 1909 and Loss: 63.082801818847656\n",
      "Iteration no: 1910 and Loss: 63.08238983154297\n",
      "Iteration no: 1911 and Loss: 63.081993103027344\n",
      "Iteration no: 1912 and Loss: 63.08158493041992\n",
      "Iteration no: 1913 and Loss: 63.08118438720703\n",
      "Iteration no: 1914 and Loss: 63.080780029296875\n",
      "Iteration no: 1915 and Loss: 63.080387115478516\n",
      "Iteration no: 1916 and Loss: 63.079986572265625\n",
      "Iteration no: 1917 and Loss: 63.079586029052734\n",
      "Iteration no: 1918 and Loss: 63.07918167114258\n",
      "Iteration no: 1919 and Loss: 63.078773498535156\n",
      "Iteration no: 1920 and Loss: 63.078392028808594\n",
      "Iteration no: 1921 and Loss: 63.07798767089844\n",
      "Iteration no: 1922 and Loss: 63.077598571777344\n",
      "Iteration no: 1923 and Loss: 63.07719421386719\n",
      "Iteration no: 1924 and Loss: 63.07680130004883\n",
      "Iteration no: 1925 and Loss: 63.0764045715332\n",
      "Iteration no: 1926 and Loss: 63.07600402832031\n",
      "Iteration no: 1927 and Loss: 63.07560348510742\n",
      "Iteration no: 1928 and Loss: 63.07521057128906\n",
      "Iteration no: 1929 and Loss: 63.07481002807617\n",
      "Iteration no: 1930 and Loss: 63.07441329956055\n",
      "Iteration no: 1931 and Loss: 63.07403564453125\n",
      "Iteration no: 1932 and Loss: 63.073631286621094\n",
      "Iteration no: 1933 and Loss: 63.073246002197266\n",
      "Iteration no: 1934 and Loss: 63.07284164428711\n",
      "Iteration no: 1935 and Loss: 63.07244873046875\n",
      "Iteration no: 1936 and Loss: 63.07206344604492\n",
      "Iteration no: 1937 and Loss: 63.07168197631836\n",
      "Iteration no: 1938 and Loss: 63.0712890625\n",
      "Iteration no: 1939 and Loss: 63.070884704589844\n",
      "Iteration no: 1940 and Loss: 63.07049560546875\n",
      "Iteration no: 1941 and Loss: 63.07010269165039\n",
      "Iteration no: 1942 and Loss: 63.06972122192383\n",
      "Iteration no: 1943 and Loss: 63.0693244934082\n",
      "Iteration no: 1944 and Loss: 63.068931579589844\n",
      "Iteration no: 1945 and Loss: 63.06853485107422\n",
      "Iteration no: 1946 and Loss: 63.068153381347656\n",
      "Iteration no: 1947 and Loss: 63.06776428222656\n",
      "Iteration no: 1948 and Loss: 63.067386627197266\n",
      "Iteration no: 1949 and Loss: 63.066986083984375\n",
      "Iteration no: 1950 and Loss: 63.06660079956055\n",
      "Iteration no: 1951 and Loss: 63.06622314453125\n",
      "Iteration no: 1952 and Loss: 63.06582260131836\n",
      "Iteration no: 1953 and Loss: 63.06543731689453\n",
      "Iteration no: 1954 and Loss: 63.06505584716797\n",
      "Iteration no: 1955 and Loss: 63.06466293334961\n",
      "Iteration no: 1956 and Loss: 63.06428527832031\n",
      "Iteration no: 1957 and Loss: 63.06388854980469\n",
      "Iteration no: 1958 and Loss: 63.063507080078125\n",
      "Iteration no: 1959 and Loss: 63.06312942504883\n",
      "Iteration no: 1960 and Loss: 63.0627555847168\n",
      "Iteration no: 1961 and Loss: 63.06236267089844\n",
      "Iteration no: 1962 and Loss: 63.06197738647461\n",
      "Iteration no: 1963 and Loss: 63.06159973144531\n",
      "Iteration no: 1964 and Loss: 63.06121063232422\n",
      "Iteration no: 1965 and Loss: 63.06084060668945\n",
      "Iteration no: 1966 and Loss: 63.06045150756836\n",
      "Iteration no: 1967 and Loss: 63.06007766723633\n",
      "Iteration no: 1968 and Loss: 63.059696197509766\n",
      "Iteration no: 1969 and Loss: 63.059322357177734\n",
      "Iteration no: 1970 and Loss: 63.05894088745117\n",
      "Iteration no: 1971 and Loss: 63.058563232421875\n",
      "Iteration no: 1972 and Loss: 63.058204650878906\n",
      "Iteration no: 1973 and Loss: 63.057838439941406\n",
      "Iteration no: 1974 and Loss: 63.057456970214844\n",
      "Iteration no: 1975 and Loss: 63.05707550048828\n",
      "Iteration no: 1976 and Loss: 63.05669403076172\n",
      "Iteration no: 1977 and Loss: 63.05632781982422\n",
      "Iteration no: 1978 and Loss: 63.05596923828125\n",
      "Iteration no: 1979 and Loss: 63.05559539794922\n",
      "Iteration no: 1980 and Loss: 63.05521011352539\n",
      "Iteration no: 1981 and Loss: 63.054847717285156\n",
      "Iteration no: 1982 and Loss: 63.05449295043945\n",
      "Iteration no: 1983 and Loss: 63.05409622192383\n",
      "Iteration no: 1984 and Loss: 63.05373764038086\n",
      "Iteration no: 1985 and Loss: 63.05335998535156\n",
      "Iteration no: 1986 and Loss: 63.05299377441406\n",
      "Iteration no: 1987 and Loss: 63.052642822265625\n",
      "Iteration no: 1988 and Loss: 63.052276611328125\n",
      "Iteration no: 1989 and Loss: 63.05190658569336\n",
      "Iteration no: 1990 and Loss: 63.05154037475586\n",
      "Iteration no: 1991 and Loss: 63.051185607910156\n",
      "Iteration no: 1992 and Loss: 63.05080795288086\n",
      "Iteration no: 1993 and Loss: 63.050445556640625\n",
      "Iteration no: 1994 and Loss: 63.05008316040039\n",
      "Iteration no: 1995 and Loss: 63.04973220825195\n",
      "Iteration no: 1996 and Loss: 63.04935073852539\n",
      "Iteration no: 1997 and Loss: 63.04901885986328\n",
      "Iteration no: 1998 and Loss: 63.048683166503906\n",
      "Iteration no: 1999 and Loss: 63.04834747314453\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-4\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# TODO recording: First run with 100 iterations, then with 2000 (don't rewrite the code, just come back to this\n",
    "# cell and  change the values here and hit shift+enter on the remaining code cells)\n",
    "\n",
    "for i in range(2000):\n",
    "    \n",
    "    y_pred = model(x_train_tensor)\n",
    "    \n",
    "    loss = loss_func(y_pred, y_train_tensor)\n",
    "    print('Iteration no: %s and Loss: %s' %(i, loss.item()))\n",
    "    \n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9238],\n",
       "        [ 0.1577],\n",
       "        [-0.2078],\n",
       "        [ 0.4265],\n",
       "        [-0.0279],\n",
       "        [ 1.1557],\n",
       "        [ 0.5982],\n",
       "        [ 0.7742],\n",
       "        [ 0.0475],\n",
       "        [-0.8778]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model(x_test_tensor)\n",
    "\n",
    "y_pred_tensor[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.9238179 ],\n",
       "       [ 0.15765102],\n",
       "       [-0.20782124],\n",
       "       [ 0.42649943],\n",
       "       [-0.02785116],\n",
       "       [ 1.1557329 ],\n",
       "       [ 0.5981958 ],\n",
       "       [ 0.7741845 ],\n",
       "       [ 0.04752433],\n",
       "       [-0.87781227]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = y_pred_tensor.detach().numpy()\n",
    "\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.scatter(x_test, y_test, s=200, c='pink', label='Actual value')\n",
    "plt.plot(x_test, y_pred, label='Predicted value', c='darkgreen')\n",
    "\n",
    "plt.xlabel('Head Size', fontsize=20)\n",
    "plt.ylabel('Brain Weight', fontsize=20)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5436508636862674"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
